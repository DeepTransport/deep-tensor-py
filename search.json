[
  {
    "objectID": "reference/SingleLayer.html",
    "href": "reference/SingleLayer.html",
    "title": "SingleLayer",
    "section": "",
    "text": "SingleLayer(self)\nConstructs the DIRT using a single layer.\nIn this setting, the DIRT algorithm reduces to the SIRT algorithm (see Cui and Dolgov, 2022).\n\n\nCui, T and Dolgov, S (2022). Deep composition of tensor-trains using squared inverse Rosenblatt transports. Foundations of Computational Mathematics 22, 1863–1922.",
    "crumbs": [
      "API Reference",
      "Bridges",
      "SingleLayer"
    ]
  },
  {
    "objectID": "reference/SingleLayer.html#references",
    "href": "reference/SingleLayer.html#references",
    "title": "SingleLayer",
    "section": "",
    "text": "Cui, T and Dolgov, S (2022). Deep composition of tensor-trains using squared inverse Rosenblatt transports. Foundations of Computational Mathematics 22, 1863–1922.",
    "crumbs": [
      "API Reference",
      "Bridges",
      "SingleLayer"
    ]
  },
  {
    "objectID": "reference/BoundedDomain.html",
    "href": "reference/BoundedDomain.html",
    "title": "BoundedDomain",
    "section": "",
    "text": "BoundedDomain(self, bounds: Tensor | None = None)\nMapping from a bounded domain to \\((-1, 1)\\).\nThis class provides a linear mapping from a bounded domain, \\((x_{0}, x_{1})\\), to \\((-1, 1)\\).\n\n\n\nbounds : Tensor | None = None\n\nA set of bounds, \\((x_{0}, x_{1})\\). The default choice is torch.tensor([-1.0, 1.0]).",
    "crumbs": [
      "API Reference",
      "Domain Mappings",
      "BoundedDomain"
    ]
  },
  {
    "objectID": "reference/BoundedDomain.html#parameters",
    "href": "reference/BoundedDomain.html#parameters",
    "title": "BoundedDomain",
    "section": "",
    "text": "bounds : Tensor | None = None\n\nA set of bounds, \\((x_{0}, x_{1})\\). The default choice is torch.tensor([-1.0, 1.0]).",
    "crumbs": [
      "API Reference",
      "Domain Mappings",
      "BoundedDomain"
    ]
  },
  {
    "objectID": "reference/SampleBasedPreconditioner.html",
    "href": "reference/SampleBasedPreconditioner.html",
    "title": "SampleBasedPreconditioner",
    "section": "",
    "text": "SampleBasedPreconditioner(\n    self,\n    samples: Tensor,\n    reference: GaussianReference | None = None,\n    perturb_eigvals: bool = False,\n    inflation: Tensor | None = None,\n)\nAn approximate linear coupling between the reference and target densities.\nBuilds an approximate linear coupling between the unit Gaussian density and the joint density of the parameters and observations, using a set of samples.\n\n\n\nsamples : Tensor\n\nAn \\(n \\times d\\) matrix containing a set of samples from the target density.\n\nreference : GaussianReference | None = None\n\nThe reference density. This must be a Gaussian density.\n\nperturb_eigvals : bool = False\n\nIf this is set to True, the diagonal of the sample covariance matrix will be multiplied by a number slightly greater than 1. This will ensure it is positive definite.\n\ninflation : Tensor | None = None\n\nTODO: write this."
  },
  {
    "objectID": "reference/SampleBasedPreconditioner.html#parameters",
    "href": "reference/SampleBasedPreconditioner.html#parameters",
    "title": "SampleBasedPreconditioner",
    "section": "",
    "text": "samples : Tensor\n\nAn \\(n \\times d\\) matrix containing a set of samples from the target density.\n\nreference : GaussianReference | None = None\n\nThe reference density. This must be a Gaussian density.\n\nperturb_eigvals : bool = False\n\nIf this is set to True, the diagonal of the sample covariance matrix will be multiplied by a number slightly greater than 1. This will ensure it is positive definite.\n\ninflation : Tensor | None = None\n\nTODO: write this."
  },
  {
    "objectID": "reference/GaussianReference.html",
    "href": "reference/GaussianReference.html",
    "title": "GaussianReference",
    "section": "",
    "text": "GaussianReference(self, domain: Domain | None = None)\nThe standard \\(d\\)-dimensional Gaussian density, \\(\\mathcal{N}(\\boldsymbol{0}_{d}, \\boldsymbol{I}_{d})\\).\nThe density can be truncated to a subinterval of the real numbers in each dimension.\n\n\n\ndomain : Domain | None = None\n\nThe domain on which the density is defined in each dimension.\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nrandom\nGenerates a set of random samples.\n\n\nsobol\nGenerates a set of QMC samples.\n\n\n\n\n\nGaussianReference.random(d: int, n: int)\nGenerates a set of random samples.\n\n\n\nd : int\n\nThe dimension of the samples.\n\nn : int\n\nThe number of samples to draw.\n\n\n\n\n\n\nrs : Tensor\n\nAn \\(n \\times d\\) matrix containing the generated samples.\n\n\n\n\n\n\nGaussianReference.sobol(d: int, n: int)\nGenerates a set of QMC samples.\n\n\n\nd : int\n\nThe dimension of the samples.\n\nn : int\n\nThe number of samples to generate.\n\n\n\n\n\n\nrs : Tensor\n\nAn \\(n \\times d\\) matrix containing the generated samples.",
    "crumbs": [
      "API Reference",
      "Reference Densities",
      "GaussianReference"
    ]
  },
  {
    "objectID": "reference/GaussianReference.html#parameters",
    "href": "reference/GaussianReference.html#parameters",
    "title": "GaussianReference",
    "section": "",
    "text": "domain : Domain | None = None\n\nThe domain on which the density is defined in each dimension.",
    "crumbs": [
      "API Reference",
      "Reference Densities",
      "GaussianReference"
    ]
  },
  {
    "objectID": "reference/GaussianReference.html#methods",
    "href": "reference/GaussianReference.html#methods",
    "title": "GaussianReference",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nrandom\nGenerates a set of random samples.\n\n\nsobol\nGenerates a set of QMC samples.\n\n\n\n\n\nGaussianReference.random(d: int, n: int)\nGenerates a set of random samples.\n\n\n\nd : int\n\nThe dimension of the samples.\n\nn : int\n\nThe number of samples to draw.\n\n\n\n\n\n\nrs : Tensor\n\nAn \\(n \\times d\\) matrix containing the generated samples.\n\n\n\n\n\n\nGaussianReference.sobol(d: int, n: int)\nGenerates a set of QMC samples.\n\n\n\nd : int\n\nThe dimension of the samples.\n\nn : int\n\nThe number of samples to generate.\n\n\n\n\n\n\nrs : Tensor\n\nAn \\(n \\times d\\) matrix containing the generated samples.",
    "crumbs": [
      "API Reference",
      "Reference Densities",
      "GaussianReference"
    ]
  },
  {
    "objectID": "reference/Fourier.html",
    "href": "reference/Fourier.html",
    "title": "Fourier",
    "section": "",
    "text": "Fourier(self, order: int)\nFourier polynomials.\n\n\n\norder : int\n\nThe number of sine functions the basis is composed of. The total number of basis functions, \\(n\\), is equal to 2*order+2.\n\n\n\n\n\nThe Fourier basis for the interval \\([-1, 1]\\), with cardinality \\(n\\), is given by \\[\n    \\left\\{1, \\sqrt{2}\\sin(\\pi x), \\dots, \\sqrt{2}\\sin(k \\pi x),\n    \\sqrt{2}\\cos(\\pi x), \\dots, \\sqrt{2}\\cos(k \\pi x),\n    \\sqrt{2}\\cos(n \\pi x / 2)\\right\\},\n\\] where \\(k = 1, 2, \\dots, \\tfrac{n}{2}-1\\).\nThe basis functions are orthonormal with respect to the (normalised) weight function given by \\[\n    \\lambda(x) = \\frac{1}{2}.\n\\]\n\n\n\nBoyd, JP (2001, Section 4.5). Chebyshev and Fourier spectral methods. Lecture Notes in Engineering, Volume 49.\nCui, T and Dolgov, S (2022). Deep composition of Tensor-Trains using squared inverse Rosenblatt transports. Foundations of Computational Mathematics, 22, 1863–1922.",
    "crumbs": [
      "API Reference",
      "Polynomial Bases",
      "Fourier"
    ]
  },
  {
    "objectID": "reference/Fourier.html#parameters",
    "href": "reference/Fourier.html#parameters",
    "title": "Fourier",
    "section": "",
    "text": "order : int\n\nThe number of sine functions the basis is composed of. The total number of basis functions, \\(n\\), is equal to 2*order+2.",
    "crumbs": [
      "API Reference",
      "Polynomial Bases",
      "Fourier"
    ]
  },
  {
    "objectID": "reference/Fourier.html#notes",
    "href": "reference/Fourier.html#notes",
    "title": "Fourier",
    "section": "",
    "text": "The Fourier basis for the interval \\([-1, 1]\\), with cardinality \\(n\\), is given by \\[\n    \\left\\{1, \\sqrt{2}\\sin(\\pi x), \\dots, \\sqrt{2}\\sin(k \\pi x),\n    \\sqrt{2}\\cos(\\pi x), \\dots, \\sqrt{2}\\cos(k \\pi x),\n    \\sqrt{2}\\cos(n \\pi x / 2)\\right\\},\n\\] where \\(k = 1, 2, \\dots, \\tfrac{n}{2}-1\\).\nThe basis functions are orthonormal with respect to the (normalised) weight function given by \\[\n    \\lambda(x) = \\frac{1}{2}.\n\\]",
    "crumbs": [
      "API Reference",
      "Polynomial Bases",
      "Fourier"
    ]
  },
  {
    "objectID": "reference/Fourier.html#references",
    "href": "reference/Fourier.html#references",
    "title": "Fourier",
    "section": "",
    "text": "Boyd, JP (2001, Section 4.5). Chebyshev and Fourier spectral methods. Lecture Notes in Engineering, Volume 49.\nCui, T and Dolgov, S (2022). Deep composition of Tensor-Trains using squared inverse Rosenblatt transports. Foundations of Computational Mathematics, 22, 1863–1922.",
    "crumbs": [
      "API Reference",
      "Polynomial Bases",
      "Fourier"
    ]
  },
  {
    "objectID": "reference/PriorTransformation.html",
    "href": "reference/PriorTransformation.html",
    "title": "PriorTransformation",
    "section": "",
    "text": "PriorTransformation(\n    self,\n    reference: Reference,\n    Q: Callable[[Tensor], Tensor],\n    Q_inv: Callable[[Tensor], Tensor],\n    neglogabsdet_Q_inv: Callable[[Tensor], Tensor],\n    dim: int,\n)\nA mapping between the prior and a reference random variable.\nTODO: there are some properties that the transformation Q needs to verify (it needs to be invertible for the pushforward density formula to make sense).\n\n\n\nreference : Reference\n\nThe density of the reference random variable.\n\nQ : Callable[[Tensor], Tensor]\n\nA function which maps from the prior to the reference distribution.\n\nQ_inv : Callable[[Tensor], Tensor]\n\nThe inverse of Q.\n\nneglogabsdet_Q_inv : Callable[[Tensor], Tensor]\n\nA function which takes as input an \\(n \\times d\\) matrix\n\ndim : int\n\nThe dimension of the parameter."
  },
  {
    "objectID": "reference/PriorTransformation.html#parameters",
    "href": "reference/PriorTransformation.html#parameters",
    "title": "PriorTransformation",
    "section": "",
    "text": "reference : Reference\n\nThe density of the reference random variable.\n\nQ : Callable[[Tensor], Tensor]\n\nA function which maps from the prior to the reference distribution.\n\nQ_inv : Callable[[Tensor], Tensor]\n\nThe inverse of Q.\n\nneglogabsdet_Q_inv : Callable[[Tensor], Tensor]\n\nA function which takes as input an \\(n \\times d\\) matrix\n\ndim : int\n\nThe dimension of the parameter."
  },
  {
    "objectID": "reference/AlgebraicMapping.html",
    "href": "reference/AlgebraicMapping.html",
    "title": "AlgebraicMapping",
    "section": "",
    "text": "AlgebraicMapping(self, scale: float | Tensor = 1.0)\nMapping from an unbounded domain to \\((-1, 1)\\).\nThis class provides a mapping from an unbounded domain, \\((-\\infty, \\infty)\\), to a bounded domain, \\((-1, 1)\\). This mapping is of the form \\[x \\mapsto \\frac{x/s}{\\sqrt{1 + (x/s)^{2}}},\\] where \\(s\\) is a scale parameter.\n\n\n\nscale : float | Tensor = 1.0\n\nThe scale parameter, \\(s\\).",
    "crumbs": [
      "API Reference",
      "Domain Mappings",
      "AlgebraicMapping"
    ]
  },
  {
    "objectID": "reference/AlgebraicMapping.html#parameters",
    "href": "reference/AlgebraicMapping.html#parameters",
    "title": "AlgebraicMapping",
    "section": "",
    "text": "scale : float | Tensor = 1.0\n\nThe scale parameter, \\(s\\).",
    "crumbs": [
      "API Reference",
      "Domain Mappings",
      "AlgebraicMapping"
    ]
  },
  {
    "objectID": "reference/UniformMapping.html",
    "href": "reference/UniformMapping.html",
    "title": "UniformMapping",
    "section": "",
    "text": "UniformMapping(self, bounds: Tensor, reference: Reference | None = None)\nA mapping between an arbitrary (product form) reference density and a uniform density with a specified set of bounds.\n\n\n\nbounds : Tensor\n\nA \\(d \\times 2\\) matrix, where each row contains the lower and upper bounds of the uniform density in each dimension.\n\nreference : Reference | None = None\n\nThe reference density. If this is not specified, it will default to the unit Gaussian in \\(d\\) dimensions with support truncated to \\([-4, 4]^{d}\\).",
    "crumbs": [
      "API Reference",
      "Preconditioners",
      "UniformMapping"
    ]
  },
  {
    "objectID": "reference/UniformMapping.html#parameters",
    "href": "reference/UniformMapping.html#parameters",
    "title": "UniformMapping",
    "section": "",
    "text": "bounds : Tensor\n\nA \\(d \\times 2\\) matrix, where each row contains the lower and upper bounds of the uniform density in each dimension.\n\nreference : Reference | None = None\n\nThe reference density. If this is not specified, it will default to the unit Gaussian in \\(d\\) dimensions with support truncated to \\([-4, 4]^{d}\\).",
    "crumbs": [
      "API Reference",
      "Preconditioners",
      "UniformMapping"
    ]
  },
  {
    "objectID": "reference/IdentityMapping.html",
    "href": "reference/IdentityMapping.html",
    "title": "IdentityMapping",
    "section": "",
    "text": "IdentityMapping(self, dim: int, reference: Reference | None = None)\nAn identity mapping.\n\n\n\ndim : int\n\nThe dimension of the mapping.\n\nreference : Reference | None = None\n\nThe reference density. If this is not specified, it will default to the unit Gaussian in \\(d\\) dimensions with support truncated to \\([-4, 4]^{d}\\).",
    "crumbs": [
      "API Reference",
      "Preconditioners",
      "IdentityMapping"
    ]
  },
  {
    "objectID": "reference/IdentityMapping.html#parameters",
    "href": "reference/IdentityMapping.html#parameters",
    "title": "IdentityMapping",
    "section": "",
    "text": "dim : int\n\nThe dimension of the mapping.\n\nreference : Reference | None = None\n\nThe reference density. If this is not specified, it will default to the unit Gaussian in \\(d\\) dimensions with support truncated to \\([-4, 4]^{d}\\).",
    "crumbs": [
      "API Reference",
      "Preconditioners",
      "IdentityMapping"
    ]
  },
  {
    "objectID": "reference/DIRT.html",
    "href": "reference/DIRT.html",
    "title": "DIRT",
    "section": "",
    "text": "DIRT(\n    self,\n    negloglik: Callable[[Tensor], Tensor],\n    neglogpri: Callable[[Tensor], Tensor],\n    preconditioner: Preconditioner,\n    bases: Basis1D | List[Basis1D],\n    bridge: Bridge | None = None,\n    tt_options: TTOptions | None = None,\n    dirt_options: DIRTOptions | None = None,\n    prev_approx: Dict[int, SIRT] | None = None,\n)\nDeep (squared) inverse Rosenblatt transport.\n\n\n\nnegloglik : Callable[[Tensor], Tensor]\n\nA function that receives an \\(n \\times d\\) matrix of samples and returns an \\(n\\)-dimensional vector containing the negative log-likelihood function evaluated at each sample.\n\nneglogpri : Callable[[Tensor], Tensor]\n\nA function that receives an \\(n \\times d\\) matrix of samples and returns an \\(n\\)-dimensional vector containing the negative log-prior density evaluated at each sample.\n\nbases : Basis1D | List[Basis1D]\n\nA list of polynomial bases (one for each dimension), or a single polynomial basis (to be used in all dimensions), used to construct the functional tensor trains at each iteration.\n\nbridge : Bridge | None = None\n\nAn object used to generate the intermediate densities to approximate at each stage of the DIRT construction.\n\ntt_options : TTOptions | None = None\n\nOptions for constructing the SIRT approximation to the ratio function (i.e., the pullback of the current bridging density under the existing composition of mappings) at each iteration.\n\ndirt_options : DIRTOptions | None = None\n\nOptions for constructing the DIRT approximation to the target density.\n\nprev_approx : Dict[int, SIRT] | None = None\n\nA dictionary containing a set of SIRTs generated as part of the construction of a previous DIRT object.\n\n\n\n\n\nCui, T and Dolgov, S (2022). Deep composition of tensor-trains using squared inverse Rosenblatt transports. Foundations of Computational Mathematics 22, 1863–1922.\n\n\n\n\n\n\nName\nDescription\n\n\n\n\neval_potential\nEvaluates the potential function.\n\n\neval_pdf\nEvaluates the density function.\n\n\neval_rt\nEvaluates the deep Rosenblatt transport.\n\n\neval_irt\nEvaluates the deep inverse Rosenblatt transport.\n\n\neval_cirt\nEvaluates the conditional inverse Rosenblatt transport.\n\n\nrandom\nGenerates a set of random samples.\n\n\nsobol\nGenerates a set of QMC samples.\n\n\n\n\n\nDIRT.eval_potential(\n    ms: Tensor,\n    n_layers: Tensor = torch.inf,\n    subset: str | None = None,\n)\nEvaluates the potential function.\nReturns the joint potential function, or the marginal potential function for the first \\(k\\) variables or the last \\(k\\) variables, corresponding to the pullback of the reference measure under a given number of layers of the DIRT.\n\n\n\nms : Tensor\n\nAn \\(n \\times k\\) matrix containing a set of samples drawn from the current DIRT approximation to the target density.\n\nn_layers : Tensor = torch.inf\n\nThe number of layers of the current DIRT construction to use.\n\nsubset : str | None = None\n\nIf the samples contain a subset of the variables, (i.e., \\(k &lt; d\\)), whether they correspond to the first \\(k\\) variables (subset='first') or the last \\(k\\) variables (subset='last').\n\n\n\n\n\n\nneglogfxs : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function of the target density evaluated at each element in xs.\n\n\n\n\n\n\nDIRT.eval_pdf(\n    ms: Tensor,\n    n_layers: Tensor = torch.inf,\n    subset: str | None = None,\n)\nEvaluates the density function.\nReturns the joint density function, or the marginal density function for the first \\(k\\) variables or the last \\(k\\) variables, corresponding to the pullback of the reference measure under a given number of layers of the DIRT.\n\n\n\nms : Tensor\n\nAn \\(n \\times k\\) matrix containing a set of samples drawn from the DIRT approximation to the target density.\n\nn_layers : Tensor = torch.inf\n\nThe number of layers of the current DIRT construction to use.\n\nsubset : str | None = None\n\nIf the samples contain a subset of the variables, (i.e., \\(k &lt; d\\)), whether they correspond to the first \\(k\\) variables (subset='first') or the last \\(k\\) variables (subset='last').\n\n\n\n\n\n\nfms : Tensor\n\nAn \\(n\\)-dimensional vector containing the value of the approximation to the target density evaluated at each element in ms.\n\n\n\n\n\n\nDIRT.eval_rt(\n    ms: Tensor,\n    n_layers: Tensor = torch.inf,\n    subset: str | None = None,\n)\nEvaluates the deep Rosenblatt transport.\n\n\n\nms : Tensor\n\nAn \\(n \\times k\\) matrix of random variables drawn from the density defined by the current DIRT.\n\nn_layers : Tensor = torch.inf\n\nThe number of layers of the deep inverse Rosenblatt transport to push the samples forward under. If not specified, the samples will be pushed forward through all the layers.\n\nsubset : str | None = None\n\nIf the samples contain a subset of the variables, (i.e., \\(k &lt; d\\)), whether they correspond to the first \\(k\\) variables (subset='first') or the last \\(k\\) variables (subset='last').\n\n\n\n\n\n\nrs : Tensor\n\nAn \\(n \\times k\\) matrix containing the composition of mappings evaluated at each value of ms.\n\nneglogfms : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function of the pullback of the reference density under the current composition of mappings, evaluated at each sample in ms.\n\n\n\n\n\n\nDIRT.eval_irt(rs: Tensor, n_layers: int = torch.inf, subset: str | None = None)\nEvaluates the deep inverse Rosenblatt transport.\n\n\n\nrs : Tensor\n\nAn \\(n \\times k\\) matrix containing samples distributed according to the reference density.\n\nn_layers : int = torch.inf\n\nThe number of layers of the deep inverse Rosenblatt transport to pull the samples back under. If not specified, the samples will be pulled back through all the layers.\n\nsubset : str | None = None\n\nIf the samples contain a subset of the variables, (i.e., \\(k &lt; d\\)), whether they correspond to the first \\(k\\) variables (subset='first') or the last \\(k\\) variables (subset='last').\n\n\n\n\n\n\nms : Tensor\n\nAn \\(n \\times k\\) matrix containing the corresponding samples from the approximation domain, after applying the deep inverse Rosenblatt transport.\n\nneglogfms : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function of the pullback of the reference density under the current composition of mappings, evaluated at each sample in xs.\n\n\n\n\n\n\nDIRT.eval_cirt(\n    ms: Tensor,\n    rs: Tensor,\n    n_layers: int = torch.inf,\n    subset: str | None = None,\n)\nEvaluates the conditional inverse Rosenblatt transport.\nReturns the conditional inverse Rosenblatt transport evaluated at a set of samples in the approximation domain.\nThe conditional inverse Rosenblatt transport takes the form\n\\[\n    Y|M = \\mathcal{T}(\\mathcal{R}_{k}(M), R),\n\\]\nwhere \\(M\\) is a \\(k\\)-dimensional random variable, \\(R\\) is a \\(n-k\\)-dimensional reference random variable, \\(\\mathcal{R}(\\,\\cdot\\,)\\) denotes the (full) Rosenblatt transport, \\(\\mathcal{T}(\\,\\cdot\\,) := \\mathcal{R}^{-1}(\\,\\cdot\\,)\\), denotes its inverse, and \\(\\mathcal{R}_{k}(\\,\\cdot\\,)\\) denotes the Rosenblatt transport for the first (or last) \\(k\\) variables.\n\n\n\nms : Tensor\n\nAn \\(n \\times k\\) matrix containing samples from the approximation domain.\n\nrs : Tensor\n\nAn \\(n \\times (d-k)\\) matrix containing samples distributed according to the reference density.\n\nn_layers : int = torch.inf\n\nThe number of layers of the deep inverse Rosenblatt transport to push the samples forward under. If not specified, the samples will be pushed forward through all the layers.\n\nsubset : str | None = None\n\nWhether ms corresponds to the first \\(k\\) variables (subset='first') of the approximation, or the last \\(k\\) variables (subset='last').\n\n\n\n\n\n\nys : Tensor\n\nAn \\(n \\times (d-k)\\) matrix containing the realisations of \\(Y\\) corresponding to the values of rs after applying the conditional inverse Rosenblatt transport.\n\nneglogfys : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function of the approximation to the conditional density of \\(Y \\textbar M\\) evaluated at each sample in rs.\n\n\n\n\n\n\nDIRT.random(n: int)\nGenerates a set of random samples.\nThe samples are distributed according to the DIRT approximation to the target density.\n\n\n\nn : int\n\nThe number of samples to generate.\n\n\n\n\n\n\nms : Tensor\n\nAn \\(n \\times d\\) matrix containing the generated samples.\n\n\n\n\n\n\nDIRT.sobol(n: int)\nGenerates a set of QMC samples.\nThe samples are distributed according to the DIRT approximation to the target density.\n\n\n\nn : int\n\nThe number of samples to generate.\n\n\n\n\n\n\nms : Tensor\n\nAn \\(n \\times d\\) matrix containing the generated samples.",
    "crumbs": [
      "API Reference",
      "Deep Inverse Rosenblatt Transport",
      "DIRT"
    ]
  },
  {
    "objectID": "reference/DIRT.html#parameters",
    "href": "reference/DIRT.html#parameters",
    "title": "DIRT",
    "section": "",
    "text": "negloglik : Callable[[Tensor], Tensor]\n\nA function that receives an \\(n \\times d\\) matrix of samples and returns an \\(n\\)-dimensional vector containing the negative log-likelihood function evaluated at each sample.\n\nneglogpri : Callable[[Tensor], Tensor]\n\nA function that receives an \\(n \\times d\\) matrix of samples and returns an \\(n\\)-dimensional vector containing the negative log-prior density evaluated at each sample.\n\nbases : Basis1D | List[Basis1D]\n\nA list of polynomial bases (one for each dimension), or a single polynomial basis (to be used in all dimensions), used to construct the functional tensor trains at each iteration.\n\nbridge : Bridge | None = None\n\nAn object used to generate the intermediate densities to approximate at each stage of the DIRT construction.\n\ntt_options : TTOptions | None = None\n\nOptions for constructing the SIRT approximation to the ratio function (i.e., the pullback of the current bridging density under the existing composition of mappings) at each iteration.\n\ndirt_options : DIRTOptions | None = None\n\nOptions for constructing the DIRT approximation to the target density.\n\nprev_approx : Dict[int, SIRT] | None = None\n\nA dictionary containing a set of SIRTs generated as part of the construction of a previous DIRT object.",
    "crumbs": [
      "API Reference",
      "Deep Inverse Rosenblatt Transport",
      "DIRT"
    ]
  },
  {
    "objectID": "reference/DIRT.html#references",
    "href": "reference/DIRT.html#references",
    "title": "DIRT",
    "section": "",
    "text": "Cui, T and Dolgov, S (2022). Deep composition of tensor-trains using squared inverse Rosenblatt transports. Foundations of Computational Mathematics 22, 1863–1922.",
    "crumbs": [
      "API Reference",
      "Deep Inverse Rosenblatt Transport",
      "DIRT"
    ]
  },
  {
    "objectID": "reference/DIRT.html#methods",
    "href": "reference/DIRT.html#methods",
    "title": "DIRT",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\neval_potential\nEvaluates the potential function.\n\n\neval_pdf\nEvaluates the density function.\n\n\neval_rt\nEvaluates the deep Rosenblatt transport.\n\n\neval_irt\nEvaluates the deep inverse Rosenblatt transport.\n\n\neval_cirt\nEvaluates the conditional inverse Rosenblatt transport.\n\n\nrandom\nGenerates a set of random samples.\n\n\nsobol\nGenerates a set of QMC samples.\n\n\n\n\n\nDIRT.eval_potential(\n    ms: Tensor,\n    n_layers: Tensor = torch.inf,\n    subset: str | None = None,\n)\nEvaluates the potential function.\nReturns the joint potential function, or the marginal potential function for the first \\(k\\) variables or the last \\(k\\) variables, corresponding to the pullback of the reference measure under a given number of layers of the DIRT.\n\n\n\nms : Tensor\n\nAn \\(n \\times k\\) matrix containing a set of samples drawn from the current DIRT approximation to the target density.\n\nn_layers : Tensor = torch.inf\n\nThe number of layers of the current DIRT construction to use.\n\nsubset : str | None = None\n\nIf the samples contain a subset of the variables, (i.e., \\(k &lt; d\\)), whether they correspond to the first \\(k\\) variables (subset='first') or the last \\(k\\) variables (subset='last').\n\n\n\n\n\n\nneglogfxs : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function of the target density evaluated at each element in xs.\n\n\n\n\n\n\nDIRT.eval_pdf(\n    ms: Tensor,\n    n_layers: Tensor = torch.inf,\n    subset: str | None = None,\n)\nEvaluates the density function.\nReturns the joint density function, or the marginal density function for the first \\(k\\) variables or the last \\(k\\) variables, corresponding to the pullback of the reference measure under a given number of layers of the DIRT.\n\n\n\nms : Tensor\n\nAn \\(n \\times k\\) matrix containing a set of samples drawn from the DIRT approximation to the target density.\n\nn_layers : Tensor = torch.inf\n\nThe number of layers of the current DIRT construction to use.\n\nsubset : str | None = None\n\nIf the samples contain a subset of the variables, (i.e., \\(k &lt; d\\)), whether they correspond to the first \\(k\\) variables (subset='first') or the last \\(k\\) variables (subset='last').\n\n\n\n\n\n\nfms : Tensor\n\nAn \\(n\\)-dimensional vector containing the value of the approximation to the target density evaluated at each element in ms.\n\n\n\n\n\n\nDIRT.eval_rt(\n    ms: Tensor,\n    n_layers: Tensor = torch.inf,\n    subset: str | None = None,\n)\nEvaluates the deep Rosenblatt transport.\n\n\n\nms : Tensor\n\nAn \\(n \\times k\\) matrix of random variables drawn from the density defined by the current DIRT.\n\nn_layers : Tensor = torch.inf\n\nThe number of layers of the deep inverse Rosenblatt transport to push the samples forward under. If not specified, the samples will be pushed forward through all the layers.\n\nsubset : str | None = None\n\nIf the samples contain a subset of the variables, (i.e., \\(k &lt; d\\)), whether they correspond to the first \\(k\\) variables (subset='first') or the last \\(k\\) variables (subset='last').\n\n\n\n\n\n\nrs : Tensor\n\nAn \\(n \\times k\\) matrix containing the composition of mappings evaluated at each value of ms.\n\nneglogfms : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function of the pullback of the reference density under the current composition of mappings, evaluated at each sample in ms.\n\n\n\n\n\n\nDIRT.eval_irt(rs: Tensor, n_layers: int = torch.inf, subset: str | None = None)\nEvaluates the deep inverse Rosenblatt transport.\n\n\n\nrs : Tensor\n\nAn \\(n \\times k\\) matrix containing samples distributed according to the reference density.\n\nn_layers : int = torch.inf\n\nThe number of layers of the deep inverse Rosenblatt transport to pull the samples back under. If not specified, the samples will be pulled back through all the layers.\n\nsubset : str | None = None\n\nIf the samples contain a subset of the variables, (i.e., \\(k &lt; d\\)), whether they correspond to the first \\(k\\) variables (subset='first') or the last \\(k\\) variables (subset='last').\n\n\n\n\n\n\nms : Tensor\n\nAn \\(n \\times k\\) matrix containing the corresponding samples from the approximation domain, after applying the deep inverse Rosenblatt transport.\n\nneglogfms : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function of the pullback of the reference density under the current composition of mappings, evaluated at each sample in xs.\n\n\n\n\n\n\nDIRT.eval_cirt(\n    ms: Tensor,\n    rs: Tensor,\n    n_layers: int = torch.inf,\n    subset: str | None = None,\n)\nEvaluates the conditional inverse Rosenblatt transport.\nReturns the conditional inverse Rosenblatt transport evaluated at a set of samples in the approximation domain.\nThe conditional inverse Rosenblatt transport takes the form\n\\[\n    Y|M = \\mathcal{T}(\\mathcal{R}_{k}(M), R),\n\\]\nwhere \\(M\\) is a \\(k\\)-dimensional random variable, \\(R\\) is a \\(n-k\\)-dimensional reference random variable, \\(\\mathcal{R}(\\,\\cdot\\,)\\) denotes the (full) Rosenblatt transport, \\(\\mathcal{T}(\\,\\cdot\\,) := \\mathcal{R}^{-1}(\\,\\cdot\\,)\\), denotes its inverse, and \\(\\mathcal{R}_{k}(\\,\\cdot\\,)\\) denotes the Rosenblatt transport for the first (or last) \\(k\\) variables.\n\n\n\nms : Tensor\n\nAn \\(n \\times k\\) matrix containing samples from the approximation domain.\n\nrs : Tensor\n\nAn \\(n \\times (d-k)\\) matrix containing samples distributed according to the reference density.\n\nn_layers : int = torch.inf\n\nThe number of layers of the deep inverse Rosenblatt transport to push the samples forward under. If not specified, the samples will be pushed forward through all the layers.\n\nsubset : str | None = None\n\nWhether ms corresponds to the first \\(k\\) variables (subset='first') of the approximation, or the last \\(k\\) variables (subset='last').\n\n\n\n\n\n\nys : Tensor\n\nAn \\(n \\times (d-k)\\) matrix containing the realisations of \\(Y\\) corresponding to the values of rs after applying the conditional inverse Rosenblatt transport.\n\nneglogfys : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function of the approximation to the conditional density of \\(Y \\textbar M\\) evaluated at each sample in rs.\n\n\n\n\n\n\nDIRT.random(n: int)\nGenerates a set of random samples.\nThe samples are distributed according to the DIRT approximation to the target density.\n\n\n\nn : int\n\nThe number of samples to generate.\n\n\n\n\n\n\nms : Tensor\n\nAn \\(n \\times d\\) matrix containing the generated samples.\n\n\n\n\n\n\nDIRT.sobol(n: int)\nGenerates a set of QMC samples.\nThe samples are distributed according to the DIRT approximation to the target density.\n\n\n\nn : int\n\nThe number of samples to generate.\n\n\n\n\n\n\nms : Tensor\n\nAn \\(n \\times d\\) matrix containing the generated samples.",
    "crumbs": [
      "API Reference",
      "Deep Inverse Rosenblatt Transport",
      "DIRT"
    ]
  },
  {
    "objectID": "reference/Lagrange1.html",
    "href": "reference/Lagrange1.html",
    "title": "Lagrange1",
    "section": "",
    "text": "Lagrange1(self, num_elems: int)\nPiecewise linear polynomials.\n\n\n\nnum_elems : int\n\nThe number of elements to use.\n\n\n\n\n\nTo construct a piecewise linear basis, we divide the interval \\([0, 1]\\) into num_elems equisized elements. Then, within each element a given function can be represented by \\[\n    f(x) \\approx f(x_{0})\n        + \\frac{f(x_{1}) - f(x_{0})}{x_{1} - x_{0}}(x - x_{0}),\n\\] where \\(x_{0}\\) and \\(x_{1}\\) denote the endpoints of the element.\nWe use piecewise cubic polynomials to represent the (conditional) CDFs corresponding to the piecewise linear representation of the (square root of) the target density function.",
    "crumbs": [
      "API Reference",
      "Polynomial Bases",
      "Lagrange1"
    ]
  },
  {
    "objectID": "reference/Lagrange1.html#parameters",
    "href": "reference/Lagrange1.html#parameters",
    "title": "Lagrange1",
    "section": "",
    "text": "num_elems : int\n\nThe number of elements to use.",
    "crumbs": [
      "API Reference",
      "Polynomial Bases",
      "Lagrange1"
    ]
  },
  {
    "objectID": "reference/Lagrange1.html#notes",
    "href": "reference/Lagrange1.html#notes",
    "title": "Lagrange1",
    "section": "",
    "text": "To construct a piecewise linear basis, we divide the interval \\([0, 1]\\) into num_elems equisized elements. Then, within each element a given function can be represented by \\[\n    f(x) \\approx f(x_{0})\n        + \\frac{f(x_{1}) - f(x_{0})}{x_{1} - x_{0}}(x - x_{0}),\n\\] where \\(x_{0}\\) and \\(x_{1}\\) denote the endpoints of the element.\nWe use piecewise cubic polynomials to represent the (conditional) CDFs corresponding to the piecewise linear representation of the (square root of) the target density function.",
    "crumbs": [
      "API Reference",
      "Polynomial Bases",
      "Lagrange1"
    ]
  },
  {
    "objectID": "reference/ImportanceSamplingResult.html",
    "href": "reference/ImportanceSamplingResult.html",
    "title": "ImportanceSamplingResult",
    "section": "",
    "text": "ImportanceSamplingResult(\n    self,\n    log_weights: Tensor,\n    log_norm: Tensor,\n    ess: Tensor,\n)\nAn object containing the results of importance sampling.\n\n\n\nlog_weights : Tensor\n\nAn \\(n\\)-dimensional vector containing the unnormalised importance weights associated with a set of samples.\n\nlog_norm : Tensor\n\nAn estimate of the logarithm of the normalising constant associated with the target density.\n\ness : Tensor\n\nAn estimate of the effective sample size of the samples.",
    "crumbs": [
      "API Reference",
      "Debiasing",
      "ImportanceSamplingResult"
    ]
  },
  {
    "objectID": "reference/ImportanceSamplingResult.html#parameters",
    "href": "reference/ImportanceSamplingResult.html#parameters",
    "title": "ImportanceSamplingResult",
    "section": "",
    "text": "log_weights : Tensor\n\nAn \\(n\\)-dimensional vector containing the unnormalised importance weights associated with a set of samples.\n\nlog_norm : Tensor\n\nAn estimate of the logarithm of the normalising constant associated with the target density.\n\ness : Tensor\n\nAn estimate of the effective sample size of the samples.",
    "crumbs": [
      "API Reference",
      "Debiasing",
      "ImportanceSamplingResult"
    ]
  },
  {
    "objectID": "reference/Legendre.html",
    "href": "reference/Legendre.html",
    "title": "Legendre",
    "section": "",
    "text": "Legendre(self, order: int)\nLegendre polynomials.\n\n\n\norder : int\n\nThe maximum order of the polynomials, \\(n\\).\n\n\n\n\n\nThe Legendre polynomials, defined on \\((-1, 1)\\), are given by the recurrence relation \\[\n    (k+1)\\hat{p}_{k+1}(x) = (2k+1)x\\hat{p}_{k}(x) - k\\hat{p}_{k-1}(x),\n        \\qquad k = 1, 2, \\dots, n-1,\n\\] where \\(\\hat{p}_{0}(x) = 1, \\hat{p}_{1}(x) = x\\). The corresponding normalised polynomials are given by \\[\n    p_{k}(x) := \\frac{\\hat{p}_{k}(x)}{2k+1},\n        \\qquad k = 0, 1, \\dots, n.\n\\]\nThe polynomials are orthonormal with respect to the (normalised) weighting function given by \\[\n    \\lambda(x) = \\frac{1}{2}.\n\\]\nWe use Chebyshev polynomials of the second kind to represent the (conditional) CDFs corresponding to the Legendre representation of the (square root of) the target density function.\n\n\n\nBoyd, JP (2001, Appendix A.2). Chebyshev and Fourier spectral methods. Lecture Notes in Engineering, Volume 49.",
    "crumbs": [
      "API Reference",
      "Polynomial Bases",
      "Legendre"
    ]
  },
  {
    "objectID": "reference/Legendre.html#parameters",
    "href": "reference/Legendre.html#parameters",
    "title": "Legendre",
    "section": "",
    "text": "order : int\n\nThe maximum order of the polynomials, \\(n\\).",
    "crumbs": [
      "API Reference",
      "Polynomial Bases",
      "Legendre"
    ]
  },
  {
    "objectID": "reference/Legendre.html#notes",
    "href": "reference/Legendre.html#notes",
    "title": "Legendre",
    "section": "",
    "text": "The Legendre polynomials, defined on \\((-1, 1)\\), are given by the recurrence relation \\[\n    (k+1)\\hat{p}_{k+1}(x) = (2k+1)x\\hat{p}_{k}(x) - k\\hat{p}_{k-1}(x),\n        \\qquad k = 1, 2, \\dots, n-1,\n\\] where \\(\\hat{p}_{0}(x) = 1, \\hat{p}_{1}(x) = x\\). The corresponding normalised polynomials are given by \\[\n    p_{k}(x) := \\frac{\\hat{p}_{k}(x)}{2k+1},\n        \\qquad k = 0, 1, \\dots, n.\n\\]\nThe polynomials are orthonormal with respect to the (normalised) weighting function given by \\[\n    \\lambda(x) = \\frac{1}{2}.\n\\]\nWe use Chebyshev polynomials of the second kind to represent the (conditional) CDFs corresponding to the Legendre representation of the (square root of) the target density function.",
    "crumbs": [
      "API Reference",
      "Polynomial Bases",
      "Legendre"
    ]
  },
  {
    "objectID": "reference/Legendre.html#references",
    "href": "reference/Legendre.html#references",
    "title": "Legendre",
    "section": "",
    "text": "Boyd, JP (2001, Appendix A.2). Chebyshev and Fourier spectral methods. Lecture Notes in Engineering, Volume 49.",
    "crumbs": [
      "API Reference",
      "Polynomial Bases",
      "Legendre"
    ]
  },
  {
    "objectID": "reference/run_importance_sampling.html",
    "href": "reference/run_importance_sampling.html",
    "title": "run_importance_sampling",
    "section": "",
    "text": "run_importance_sampling(\n    neglogfxs_irt: Tensor,\n    neglogfxs_exact: Tensor,\n    self_normalised: bool = False,\n)\nComputes the importance weights associated with a set of samples.\n\n\n\nneglogfxs_irt : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function associated with the DIRT object evaluated at each sample.\n\nneglogfxs_exact : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function associated with the target density evaluated at each sample.\n\nself_normalised : bool = False\n\nWhether the target density is normalised. If not, the log of the normalising constant will be estimated using the weights.\n\n\n\n\n\n\nres : ImportanceSamplingResult\n\nA structure containing the log-importance weights (normalised, if self_normalised=False), the estimate of the log-normalising constant of the target density (if self_normalised=False), and the effective sample size.",
    "crumbs": [
      "API Reference",
      "Debiasing",
      "run_importance_sampling"
    ]
  },
  {
    "objectID": "reference/run_importance_sampling.html#parameters",
    "href": "reference/run_importance_sampling.html#parameters",
    "title": "run_importance_sampling",
    "section": "",
    "text": "neglogfxs_irt : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function associated with the DIRT object evaluated at each sample.\n\nneglogfxs_exact : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function associated with the target density evaluated at each sample.\n\nself_normalised : bool = False\n\nWhether the target density is normalised. If not, the log of the normalising constant will be estimated using the weights.",
    "crumbs": [
      "API Reference",
      "Debiasing",
      "run_importance_sampling"
    ]
  },
  {
    "objectID": "reference/run_importance_sampling.html#returns",
    "href": "reference/run_importance_sampling.html#returns",
    "title": "run_importance_sampling",
    "section": "",
    "text": "res : ImportanceSamplingResult\n\nA structure containing the log-importance weights (normalised, if self_normalised=False), the estimate of the log-normalising constant of the target density (if self_normalised=False), and the effective sample size.",
    "crumbs": [
      "API Reference",
      "Debiasing",
      "run_importance_sampling"
    ]
  },
  {
    "objectID": "reference/UniformReference.html",
    "href": "reference/UniformReference.html",
    "title": "UniformReference",
    "section": "",
    "text": "UniformReference(self)\nThe standard \\(d\\)-dimensional uniform density, \\(\\mathcal{U}([0, 1]^{d})\\).\n\n\n\n\n\nName\nDescription\n\n\n\n\nrandom\nGenerates a set of random samples.\n\n\nsobol\nGenerates a set of QMC samples.\n\n\n\n\n\nUniformReference.random(d: int, n: int)\nGenerates a set of random samples.\n\n\n\nd : int\n\nThe dimension of the samples.\n\nn : int\n\nThe number of samples to draw.\n\n\n\n\n\n\nrs : Tensor\n\nAn \\(n \\times d\\) matrix containing the generated samples.\n\n\n\n\n\n\nUniformReference.sobol(d: int, n: int)\nGenerates a set of QMC samples.\n\n\n\nd : int\n\nThe dimension of the samples.\n\nn : int\n\nThe number of samples to generate.\n\n\n\n\n\n\nrs : Tensor\n\nAn \\(n \\times d\\) matrix containing the generated samples.",
    "crumbs": [
      "API Reference",
      "Reference Densities",
      "UniformReference"
    ]
  },
  {
    "objectID": "reference/UniformReference.html#methods",
    "href": "reference/UniformReference.html#methods",
    "title": "UniformReference",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nrandom\nGenerates a set of random samples.\n\n\nsobol\nGenerates a set of QMC samples.\n\n\n\n\n\nUniformReference.random(d: int, n: int)\nGenerates a set of random samples.\n\n\n\nd : int\n\nThe dimension of the samples.\n\nn : int\n\nThe number of samples to draw.\n\n\n\n\n\n\nrs : Tensor\n\nAn \\(n \\times d\\) matrix containing the generated samples.\n\n\n\n\n\n\nUniformReference.sobol(d: int, n: int)\nGenerates a set of QMC samples.\n\n\n\nd : int\n\nThe dimension of the samples.\n\nn : int\n\nThe number of samples to generate.\n\n\n\n\n\n\nrs : Tensor\n\nAn \\(n \\times d\\) matrix containing the generated samples.",
    "crumbs": [
      "API Reference",
      "Reference Densities",
      "UniformReference"
    ]
  },
  {
    "objectID": "examples/index.html",
    "href": "examples/index.html",
    "title": "Examples",
    "section": "",
    "text": "This page contains examples demonstrating the use of \\(\\texttt{deep\\_tensor}\\).",
    "crumbs": [
      "Examples"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Installation",
    "section": "",
    "text": "The \\(\\texttt{deep\\_tensor}\\) package contains a PyTorch implementation of the deep inverse Rosenblatt transport (DIRT) algorithm introduced by Cui and Dolgov (2022).\n\nInstallation\nComing soon…\n\n\nGetting Started\nCheck out the examples page and API reference for help getting started with \\(\\texttt{deep\\_tensor}\\).\n\n\n\n\n\nReferences\n\nCui, Tiangang, and Sergey Dolgov. 2022. “Deep Composition of Tensor-Trains Using Squared Inverse Rosenblatt Transports.” Foundations of Computational Mathematics 22 (6): 1863–1922."
  },
  {
    "objectID": "examples/sir.html",
    "href": "examples/sir.html",
    "title": "SIR Model",
    "section": "",
    "text": "Here, we characterise the posterior distribution associated with a susceptible-infectious-recovered (SIR) model. We will consider a similar setup to that described in Cui, Dolgov, and Zahm (2023).",
    "crumbs": [
      "Examples",
      "SIR Model"
    ]
  },
  {
    "objectID": "examples/sir.html#dirt-construction",
    "href": "examples/sir.html#dirt-construction",
    "title": "SIR Model",
    "section": "DIRT Construction",
    "text": "DIRT Construction\nThere are several objects we must create prior to building a DIRT approximation to the posterior. Here, we describe the key ones. For a full list, see the API reference.\n\nLikelihood and Prior\nWe first define functions that return the potential function (i.e., the negative logarithm) of the likelihood and the prior density.\n\n\n\n\n\n\nNote\n\n\n\nThe negloglik and neglogpri functions must be able to handle multiple sets of parameters. Each function should accept as input a two-dimensional torch.Tensor, where each row contains a sample, and return a one-dimensional torch.Tensor object containing the negative log-likelihood, or negative log-prior density, evaluated at each sample.\n\n\n\ndef negloglik(xs: torch.Tensor) -&gt; torch.Tensor:\n    ys = model.solve_fwd(xs)\n    return 0.5 * (ys - ys_obs).square().sum(dim=1)\n\ndef neglogpri(xs: torch.Tensor) -&gt; torch.Tensor:\n    neglogpris = torch.full((xs.shape[0],), -torch.tensor(0.25).log())\n    neglogpris[xs[:, 0] &lt; 0.0] = torch.inf \n    neglogpris[xs[:, 1] &gt; 2.0] = torch.inf\n    return neglogpris\n\n\n\nReference Density and Preconditioner\nNext, we specify a product-form reference density. A good choice in most cases is the standard Gaussian density.\nWe must also specify a preconditioner. Recall that the DIRT object provides a coupling between a product-form reference density and an approximation to the target density. A preconditioner can be considered an initial guess as to what this coupling is.\nChoosing an suitable preconditioner can reduce the computational expense required to construct the DIRT object significantly. In the context of a Bayesian inverse problem, a suitable choice is a mapping from the reference density to the prior.\n\nbounds = torch.tensor([[0.0, 2.0], [0.0, 2.0]])\nreference = dt.GaussianReference()\npreconditioner = dt.UniformMapping(bounds, reference)\n\n\n\nApproximation Bases\nNext, we specify the polynomial basis which will be used when approximating the marginal PDFs and CDFs required to define the (inverse) Rosenblatt transport. We can specify a list of bases in each dimension, or a single basis (which will be used in all dimensions).\nHere, we use a piecewise linear basis with 20 equisized elements in each dimension.\n\nbases = dt.Lagrange1(num_elems=20)\n\n\n\nDIRT Object\nNow we can construct the DIRT object.\n\ndirt = dt.DIRT(\n    negloglik, \n    neglogpri, \n    preconditioner, \n    bases,\n    tt_options=dt.TTOptions(verbose=False),\n    dirt_options=dt.DIRTOptions(verbose=False)\n)\n\nFigure 1 shows a plot of the DIRT approximation to the posterior, as well as the true posterior for comparison. The posterior is very concentrated in comparison to the prior (particularly for parameter \\(\\beta\\)).\n\n\nCode\nn_grid = 300\nb_grid = torch.linspace(0.05, 0.14, n_grid)\ng_grid = torch.linspace(0.80, 1.40, n_grid)\ngrid = torch.tensor([[b, g] for g in g_grid for b in b_grid])\n\nfig, axes = plt.subplots(1, 2, figsize=(7, 3.5), sharex=True, sharey=True)\n\npdf_true = torch.exp(-(negloglik(grid) + neglogpri(grid)))\npdf_true = pdf_true.reshape(n_grid, n_grid)\n\npdf_dirt = dirt.eval_pdf(grid)\npdf_dirt = pdf_dirt.reshape(n_grid, n_grid)\n\naxes[0].pcolormesh(b_grid, g_grid, pdf_true)\naxes[1].pcolormesh(b_grid, g_grid, pdf_dirt)\n\naxes[0].set_ylabel(r\"$\\gamma$\")\n\nfor ax in axes:\n    ax.set_xlabel(r\"$\\beta$\")\n    ax.set_box_aspect(1)\n\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: A comparison between the true posterior density (left) and the DIRT approximation (right).\n\n\n\n\n\nWe can sample from the approximation to the posterior by drawing a set of samples from the reference density and calling the eval_irt method of the DIRT object. Note that the eval_irt method also returns the potential function of the DIRT approximation to the target density evaluated at each sample.\n\nrs = dirt.reference.random(d=dirt.dim, n=20)\nsamples, potentials = dirt.eval_irt(rs)\n\nFigure 2 shows a plot of the samples.\n\n\nCode\nfig, ax = plt.subplots(figsize=(7, 3.5), sharex=True, sharey=True)\n\nax.pcolormesh(b_grid, g_grid, pdf_dirt)\nax.scatter(*samples.T, c=\"white\", s=4)\n\nax.set_xlabel(r\"$\\beta$\")\nax.set_ylabel(r\"$\\gamma$\")\nax.set_box_aspect(1)\n\nplt.show()\n\n\n\n\n\n\n\n\nFigure 2: Samples from the DIRT approximation to the posterior.",
    "crumbs": [
      "Examples",
      "SIR Model"
    ]
  },
  {
    "objectID": "examples/sir.html#debiasing",
    "href": "examples/sir.html#debiasing",
    "title": "SIR Model",
    "section": "Debiasing",
    "text": "Debiasing\nWhile the DIRT approximation to the posterior density is quite accurate, we may still wish to correct for bias in the approximation results. We can do this by using the DIRT density as part of a Markov chain Monte Carlo (MCMC) sampler, or as a proposal density for importance sampling.\n\nMCMC Sampling\nFirst, we will illustrate how to use the DIRT density as part of an MCMC sampler. The simplest sampler, which we demonstrate here, is an independence sampler using the DIRT density as a proposal density.\n\ndef potential(xs: torch.Tensor) -&gt; torch.Tensor:\n    return negloglik(xs) + neglogpri(xs)\n\nrs = dirt.reference.random(d=dirt.dim, n=1000)\nsamples, potentials_irt = dirt.eval_irt(rs)\npotentials_true = potential(samples)\n\nres = dt.run_independence_sampler(samples, potentials_irt, potentials_true)\nprint(f\"Acceptance rate: {res.acceptance_rate:.4f}\")\n\nAcceptance rate: 0.9100\n\n\nFigure 3 shows the first 20 points of the simulated Markov chain.\n\n\nCode\nfig, ax = plt.subplots(figsize=(7, 3.5), sharex=True, sharey=True)\n\nax.pcolormesh(b_grid, g_grid, pdf_true)\nax.scatter(*res.xs[:20].T, c=\"white\", s=4)\nax.plot(*res.xs[:20].T, c=\"white\", lw=0.4)\n\nax.set_xlabel(r\"$\\beta$\")\nax.set_ylabel(r\"$\\gamma$\")\nax.set_box_aspect(1)\n\nplt.show()\n\n\n\n\n\n\n\n\nFigure 3: The first 20 points of the simulated Markov chain, plotted on top of the true posterior density.\n\n\n\n\n\n\n\nImportance Sampling\nAs an alternative to MCMC, we can also apply importance sampling to reweight samples from the DIRT approximation appropriately.\n\nres = dt.run_importance_sampling(potentials_irt, potentials_true)\nprint(f\"ESS: {res.ess:.2f}\")\n\nESS: 976.20\n\n\nAs expected, the effective sample size (ESS) is almost equal to the number of samples.",
    "crumbs": [
      "Examples",
      "SIR Model"
    ]
  },
  {
    "objectID": "reference/TTDIRT.html",
    "href": "reference/TTDIRT.html",
    "title": "TTDIRT",
    "section": "",
    "text": "TTDIRT(\n    self,\n    negloglik: Callable[[Tensor], Tensor],\n    prior: PriorTransformation,\n    bases: Basis1D | List[Basis1D],\n    bridge: Bridge | None = None,\n    sirt_options: TTOptions | None = None,\n    dirt_options: DIRTOptions | None = None,\n    prev_approx: Dict[int, TTSIRT] | None = None,\n)\nDeep (squared) inverse Rosenblatt transport.\n\n\n\nnegloglik : Callable[[Tensor], Tensor]\n\nA function that receives an \\(n \\times d\\) matrix of samples and returns an \\(n\\)-dimensional vector containing the negative log-likelihood function evaluated at each sample.\n\nprior : PriorTransformation\n\nAn object which provides a coupling between the prior and a product-form reference density.\n\nbases : Basis1D | List[Basis1D]\n\nA list of polynomial bases (one for each dimension), or a single polynomial basis (to be used in all dimensions), used to construct the functional tensor trains at each iteration.\n\nbridge : Bridge | None = None\n\nAn object used to generate the intermediate densities to approximate at each stage of the DIRT construction.\n\nsirt_options : TTOptions | None = None\n\nOptions for constructing the SIRT approximation to the ratio function (i.e., the pullback of the current bridging density under the existing composition of mappings) at each iteration.\n\ndirt_options : DIRTOptions | None = None\n\nOptions for constructing the DIRT approximation to the target density.\n\nprev_approx : Dict[int, TTSIRT] | None = None\n\nA dictionary containing a set of SIRTs generated as part of the construction of a previous DIRT object.\n\n\n\n\n\nCui, T and Dolgov, S (2022). Deep composition of tensor-trains using squared inverse Rosenblatt transports. Foundations of Computational Mathematics 22, 1863–1922.\n\n\n\n\n\n\nName\nDescription\n\n\n\n\neval_potential\nEvaluates the potential function.\n\n\neval_pdf\nEvaluates the density function.\n\n\neval_rt\nEvaluates the deep Rosenblatt transport.\n\n\neval_irt\nEvaluates the deep inverse Rosenblatt transport.\n\n\neval_cirt\nEvaluates the conditional inverse Rosenblatt transport.\n\n\nrandom\nGenerates a set of random samples.\n\n\nsobol\nGenerates a set of QMC samples.\n\n\n\n\n\nTTDIRT.eval_potential(\n    ms: Tensor,\n    n_layers: Tensor = torch.inf,\n    subset: str | None = None,\n)\nEvaluates the potential function.\nReturns the joint potential function, or the marginal potential function for the first \\(k\\) variables or the last \\(k\\) variables, corresponding to the pullback of the reference measure under a given number of layers of the DIRT.\n\n\n\nms : Tensor\n\nAn \\(n \\times k\\) matrix containing a set of samples drawn from the current DIRT approximation to the target density.\n\nn_layers : Tensor = torch.inf\n\nThe number of layers of the current DIRT construction to use.\n\nsubset : str | None = None\n\nIf the samples contain a subset of the variables, (i.e., \\(k &lt; d\\)), whether they correspond to the first \\(k\\) variables (subset='first') or the last \\(k\\) variables (subset='last').\n\n\n\n\n\n\nneglogfxs : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function of the target density evaluated at each element in xs.\n\n\n\n\n\n\nTTDIRT.eval_pdf(\n    ms: Tensor,\n    n_layers: Tensor = torch.inf,\n    subset: str | None = None,\n)\nEvaluates the density function.\nReturns the joint density function, or the marginal density function for the first \\(k\\) variables or the last \\(k\\) variables, corresponding to the pullback of the reference measure under a given number of layers of the DIRT.\n\n\n\nms : Tensor\n\nAn \\(n \\times k\\) matrix containing a set of samples drawn from the DIRT approximation to the target density.\n\nn_layers : Tensor = torch.inf\n\nThe number of layers of the current DIRT construction to use.\n\nsubset : str | None = None\n\nIf the samples contain a subset of the variables, (i.e., \\(k &lt; d\\)), whether they correspond to the first \\(k\\) variables (subset='first') or the last \\(k\\) variables (subset='last').\n\n\n\n\n\n\nfms : Tensor\n\nAn \\(n\\)-dimensional vector containing the value of the approximation to the target density evaluated at each element in ms.\n\n\n\n\n\n\nTTDIRT.eval_rt(\n    ms: Tensor,\n    n_layers: Tensor = torch.inf,\n    subset: str | None = None,\n)\nEvaluates the deep Rosenblatt transport.\n\n\n\nms : Tensor\n\nAn \\(n \\times k\\) matrix of random variables drawn from the density defined by the current DIRT.\n\nn_layers : Tensor = torch.inf\n\nThe number of layers of the deep inverse Rosenblatt transport to push the samples forward under. If not specified, the samples will be pushed forward through all the layers.\n\nsubset : str | None = None\n\nIf the samples contain a subset of the variables, (i.e., \\(k &lt; d\\)), whether they correspond to the first \\(k\\) variables (subset='first') or the last \\(k\\) variables (subset='last').\n\n\n\n\n\n\nrs : Tensor\n\nAn \\(n \\times k\\) matrix containing the composition of mappings evaluated at each value of ms.\n\nneglogfms : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function of the pullback of the reference density under the current composition of mappings, evaluated at each sample in ms.\n\n\n\n\n\n\nTTDIRT.eval_irt(\n    rs: Tensor,\n    n_layers: int = torch.inf,\n    subset: str | None = None,\n)\nEvaluates the deep inverse Rosenblatt transport.\n\n\n\nrs : Tensor\n\nAn \\(n \\times k\\) matrix containing samples distributed according to the reference density.\n\nn_layers : int = torch.inf\n\nThe number of layers of the deep inverse Rosenblatt transport to pull the samples back under. If not specified, the samples will be pulled back through all the layers.\n\nsubset : str | None = None\n\nIf the samples contain a subset of the variables, (i.e., \\(k &lt; d\\)), whether they correspond to the first \\(k\\) variables (subset='first') or the last \\(k\\) variables (subset='last').\n\n\n\n\n\n\nms : Tensor\n\nAn \\(n \\times k\\) matrix containing the corresponding samples from the approximation domain, after applying the deep inverse Rosenblatt transport.\n\nneglogfms : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function of the pullback of the reference density under the current composition of mappings, evaluated at each sample in xs.\n\n\n\n\n\n\nTTDIRT.eval_cirt(\n    ms: Tensor,\n    rs: Tensor,\n    n_layers: int = torch.inf,\n    subset: str | None = None,\n)\nEvaluates the conditional inverse Rosenblatt transport.\nReturns the conditional inverse Rosenblatt transport evaluated at a set of samples in the approximation domain.\nThe conditional inverse Rosenblatt transport takes the form\n\\[\n    Y|M = \\mathcal{R}^{-1}(\\mathcal{R}_{k}(M), R),\n\\]\nwhere \\(M\\) is a \\(k\\)-dimensional random variable, \\(R\\) is a \\(n-k\\)-dimensional reference random variable, \\(\\mathcal{R}(\\,\\cdot\\,)\\) denotes the (full) Rosenblatt transport, and \\(\\mathcal{R}_{k}(\\,\\cdot\\,)\\) denotes the Rosenblatt transport for the first (or last) \\(k\\) variables.\n\n\n\nms : Tensor\n\nAn \\(n \\times k\\) matrix containing samples from the approximation domain.\n\nrs : Tensor\n\nAn \\(n \\times (d-k)\\) matrix containing samples distributed according to the reference density.\n\nn_layers : int = torch.inf\n\nThe number of layers of the deep inverse Rosenblatt transport to push the samples forward under. If not specified, the samples will be pushed forward through all the layers.\n\nsubset : str | None = None\n\nWhether ms corresponds to the first \\(k\\) variables (subset='first') of the approximation, or the last \\(k\\) variables (subset='last').\n\n\n\n\n\n\nys : Tensor\n\nAn \\(n \\times (d-k)\\) matrix containing the realisations of \\(Y\\) corresponding to the values of rs after applying the conditional inverse Rosenblatt transport.\n\nneglogfys : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function of the approximation to the conditional density of \\(Y \\textbar M\\) evaluated at each sample in rs.\n\n\n\n\n\n\nTTDIRT.random(n: int)\nGenerates a set of random samples.\nThe samples are distributed according to the DIRT approximation to the target posterior.\n\n\n\nn : int\n\nThe number of samples to generate.\n\n\n\n\n\n\nms : Tensor\n\nAn \\(n \\times d\\) matrix containing the generated samples.\n\n\n\n\n\n\nTTDIRT.sobol(n: int)\nGenerates a set of QMC samples.\nThe samples are distributed according to the DIRT approximation to the target posterior.\n\n\n\nn : int\n\nThe number of samples to generate.\n\n\n\n\n\n\nms : Tensor\n\nAn \\(n \\times d\\) matrix containing the generated samples."
  },
  {
    "objectID": "reference/TTDIRT.html#parameters",
    "href": "reference/TTDIRT.html#parameters",
    "title": "TTDIRT",
    "section": "",
    "text": "negloglik : Callable[[Tensor], Tensor]\n\nA function that receives an \\(n \\times d\\) matrix of samples and returns an \\(n\\)-dimensional vector containing the negative log-likelihood function evaluated at each sample.\n\nprior : PriorTransformation\n\nAn object which provides a coupling between the prior and a product-form reference density.\n\nbases : Basis1D | List[Basis1D]\n\nA list of polynomial bases (one for each dimension), or a single polynomial basis (to be used in all dimensions), used to construct the functional tensor trains at each iteration.\n\nbridge : Bridge | None = None\n\nAn object used to generate the intermediate densities to approximate at each stage of the DIRT construction.\n\nsirt_options : TTOptions | None = None\n\nOptions for constructing the SIRT approximation to the ratio function (i.e., the pullback of the current bridging density under the existing composition of mappings) at each iteration.\n\ndirt_options : DIRTOptions | None = None\n\nOptions for constructing the DIRT approximation to the target density.\n\nprev_approx : Dict[int, TTSIRT] | None = None\n\nA dictionary containing a set of SIRTs generated as part of the construction of a previous DIRT object."
  },
  {
    "objectID": "reference/TTDIRT.html#references",
    "href": "reference/TTDIRT.html#references",
    "title": "TTDIRT",
    "section": "",
    "text": "Cui, T and Dolgov, S (2022). Deep composition of tensor-trains using squared inverse Rosenblatt transports. Foundations of Computational Mathematics 22, 1863–1922."
  },
  {
    "objectID": "reference/TTDIRT.html#methods",
    "href": "reference/TTDIRT.html#methods",
    "title": "TTDIRT",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\neval_potential\nEvaluates the potential function.\n\n\neval_pdf\nEvaluates the density function.\n\n\neval_rt\nEvaluates the deep Rosenblatt transport.\n\n\neval_irt\nEvaluates the deep inverse Rosenblatt transport.\n\n\neval_cirt\nEvaluates the conditional inverse Rosenblatt transport.\n\n\nrandom\nGenerates a set of random samples.\n\n\nsobol\nGenerates a set of QMC samples.\n\n\n\n\n\nTTDIRT.eval_potential(\n    ms: Tensor,\n    n_layers: Tensor = torch.inf,\n    subset: str | None = None,\n)\nEvaluates the potential function.\nReturns the joint potential function, or the marginal potential function for the first \\(k\\) variables or the last \\(k\\) variables, corresponding to the pullback of the reference measure under a given number of layers of the DIRT.\n\n\n\nms : Tensor\n\nAn \\(n \\times k\\) matrix containing a set of samples drawn from the current DIRT approximation to the target density.\n\nn_layers : Tensor = torch.inf\n\nThe number of layers of the current DIRT construction to use.\n\nsubset : str | None = None\n\nIf the samples contain a subset of the variables, (i.e., \\(k &lt; d\\)), whether they correspond to the first \\(k\\) variables (subset='first') or the last \\(k\\) variables (subset='last').\n\n\n\n\n\n\nneglogfxs : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function of the target density evaluated at each element in xs.\n\n\n\n\n\n\nTTDIRT.eval_pdf(\n    ms: Tensor,\n    n_layers: Tensor = torch.inf,\n    subset: str | None = None,\n)\nEvaluates the density function.\nReturns the joint density function, or the marginal density function for the first \\(k\\) variables or the last \\(k\\) variables, corresponding to the pullback of the reference measure under a given number of layers of the DIRT.\n\n\n\nms : Tensor\n\nAn \\(n \\times k\\) matrix containing a set of samples drawn from the DIRT approximation to the target density.\n\nn_layers : Tensor = torch.inf\n\nThe number of layers of the current DIRT construction to use.\n\nsubset : str | None = None\n\nIf the samples contain a subset of the variables, (i.e., \\(k &lt; d\\)), whether they correspond to the first \\(k\\) variables (subset='first') or the last \\(k\\) variables (subset='last').\n\n\n\n\n\n\nfms : Tensor\n\nAn \\(n\\)-dimensional vector containing the value of the approximation to the target density evaluated at each element in ms.\n\n\n\n\n\n\nTTDIRT.eval_rt(\n    ms: Tensor,\n    n_layers: Tensor = torch.inf,\n    subset: str | None = None,\n)\nEvaluates the deep Rosenblatt transport.\n\n\n\nms : Tensor\n\nAn \\(n \\times k\\) matrix of random variables drawn from the density defined by the current DIRT.\n\nn_layers : Tensor = torch.inf\n\nThe number of layers of the deep inverse Rosenblatt transport to push the samples forward under. If not specified, the samples will be pushed forward through all the layers.\n\nsubset : str | None = None\n\nIf the samples contain a subset of the variables, (i.e., \\(k &lt; d\\)), whether they correspond to the first \\(k\\) variables (subset='first') or the last \\(k\\) variables (subset='last').\n\n\n\n\n\n\nrs : Tensor\n\nAn \\(n \\times k\\) matrix containing the composition of mappings evaluated at each value of ms.\n\nneglogfms : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function of the pullback of the reference density under the current composition of mappings, evaluated at each sample in ms.\n\n\n\n\n\n\nTTDIRT.eval_irt(\n    rs: Tensor,\n    n_layers: int = torch.inf,\n    subset: str | None = None,\n)\nEvaluates the deep inverse Rosenblatt transport.\n\n\n\nrs : Tensor\n\nAn \\(n \\times k\\) matrix containing samples distributed according to the reference density.\n\nn_layers : int = torch.inf\n\nThe number of layers of the deep inverse Rosenblatt transport to pull the samples back under. If not specified, the samples will be pulled back through all the layers.\n\nsubset : str | None = None\n\nIf the samples contain a subset of the variables, (i.e., \\(k &lt; d\\)), whether they correspond to the first \\(k\\) variables (subset='first') or the last \\(k\\) variables (subset='last').\n\n\n\n\n\n\nms : Tensor\n\nAn \\(n \\times k\\) matrix containing the corresponding samples from the approximation domain, after applying the deep inverse Rosenblatt transport.\n\nneglogfms : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function of the pullback of the reference density under the current composition of mappings, evaluated at each sample in xs.\n\n\n\n\n\n\nTTDIRT.eval_cirt(\n    ms: Tensor,\n    rs: Tensor,\n    n_layers: int = torch.inf,\n    subset: str | None = None,\n)\nEvaluates the conditional inverse Rosenblatt transport.\nReturns the conditional inverse Rosenblatt transport evaluated at a set of samples in the approximation domain.\nThe conditional inverse Rosenblatt transport takes the form\n\\[\n    Y|M = \\mathcal{R}^{-1}(\\mathcal{R}_{k}(M), R),\n\\]\nwhere \\(M\\) is a \\(k\\)-dimensional random variable, \\(R\\) is a \\(n-k\\)-dimensional reference random variable, \\(\\mathcal{R}(\\,\\cdot\\,)\\) denotes the (full) Rosenblatt transport, and \\(\\mathcal{R}_{k}(\\,\\cdot\\,)\\) denotes the Rosenblatt transport for the first (or last) \\(k\\) variables.\n\n\n\nms : Tensor\n\nAn \\(n \\times k\\) matrix containing samples from the approximation domain.\n\nrs : Tensor\n\nAn \\(n \\times (d-k)\\) matrix containing samples distributed according to the reference density.\n\nn_layers : int = torch.inf\n\nThe number of layers of the deep inverse Rosenblatt transport to push the samples forward under. If not specified, the samples will be pushed forward through all the layers.\n\nsubset : str | None = None\n\nWhether ms corresponds to the first \\(k\\) variables (subset='first') of the approximation, or the last \\(k\\) variables (subset='last').\n\n\n\n\n\n\nys : Tensor\n\nAn \\(n \\times (d-k)\\) matrix containing the realisations of \\(Y\\) corresponding to the values of rs after applying the conditional inverse Rosenblatt transport.\n\nneglogfys : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function of the approximation to the conditional density of \\(Y \\textbar M\\) evaluated at each sample in rs.\n\n\n\n\n\n\nTTDIRT.random(n: int)\nGenerates a set of random samples.\nThe samples are distributed according to the DIRT approximation to the target posterior.\n\n\n\nn : int\n\nThe number of samples to generate.\n\n\n\n\n\n\nms : Tensor\n\nAn \\(n \\times d\\) matrix containing the generated samples.\n\n\n\n\n\n\nTTDIRT.sobol(n: int)\nGenerates a set of QMC samples.\nThe samples are distributed according to the DIRT approximation to the target posterior.\n\n\n\nn : int\n\nThe number of samples to generate.\n\n\n\n\n\n\nms : Tensor\n\nAn \\(n \\times d\\) matrix containing the generated samples."
  },
  {
    "objectID": "reference/Preconditioner.html",
    "href": "reference/Preconditioner.html",
    "title": "Preconditioner",
    "section": "",
    "text": "Preconditioner(\n    self,\n    reference: Reference,\n    Q: Callable[[Tensor], Tensor],\n    Q_inv: Callable[[Tensor], Tensor],\n    neglogdet_Q: Callable[[Tensor], Tensor],\n    neglogdet_Q_inv: Callable[[Tensor], Tensor],\n    dim: int,\n)\nA mapping between the prior and a reference random variable.\nThis mapping needs to be triangular. - If the mapping is lower triangular, one can evaluate the marginal densities of the corresponding DIRT object in the first \\(k\\) variables, and condition on the first \\(k\\) variables, where \\(1 \\leq k \\leq d\\). - If the mapping is upper triangular, one can evaluate the marginal densities of the corresponding DIRT object in the last \\(k\\) variables, and condition on the final \\(k\\) variables, where \\(1 \\leq k \\leq d\\).\n\n\n\nreference : Reference\n\nThe density of the reference random variable.\n\nQ : Callable[[Tensor], Tensor]\n\nA function which maps from the reference distribution to the prior.\n\nQ_inv : Callable[[Tensor], Tensor]\n\nThe inverse of Q.\n\nneglogdet_Q : Callable[[Tensor], Tensor]\n\nTODO\n\nneglogdet_Q_inv : Callable[[Tensor], Tensor]\n\nTODO\n\ndim : int\n\nThe dimension of the parameter.",
    "crumbs": [
      "API Reference",
      "Preconditioners",
      "Preconditioner"
    ]
  },
  {
    "objectID": "reference/Preconditioner.html#parameters",
    "href": "reference/Preconditioner.html#parameters",
    "title": "Preconditioner",
    "section": "",
    "text": "reference : Reference\n\nThe density of the reference random variable.\n\nQ : Callable[[Tensor], Tensor]\n\nA function which maps from the reference distribution to the prior.\n\nQ_inv : Callable[[Tensor], Tensor]\n\nThe inverse of Q.\n\nneglogdet_Q : Callable[[Tensor], Tensor]\n\nTODO\n\nneglogdet_Q_inv : Callable[[Tensor], Tensor]\n\nTODO\n\ndim : int\n\nThe dimension of the parameter.",
    "crumbs": [
      "API Reference",
      "Preconditioners",
      "Preconditioner"
    ]
  },
  {
    "objectID": "reference/DIRTPreconditioner.html",
    "href": "reference/DIRTPreconditioner.html",
    "title": "DIRTPreconditioner",
    "section": "",
    "text": "DIRTPreconditioner(self, dirt, mapping: str = 'lower')\nA preconditioner built using a previously constructed DIRT object.\n\n\n\ndirt : \n\nA previously constructed DIRT object.\n\nmapping : str = 'lower'\n\nWhether the transformations associated with the DIRT object are lower or upper triangular."
  },
  {
    "objectID": "reference/DIRTPreconditioner.html#parameters",
    "href": "reference/DIRTPreconditioner.html#parameters",
    "title": "DIRTPreconditioner",
    "section": "",
    "text": "dirt : \n\nA previously constructed DIRT object.\n\nmapping : str = 'lower'\n\nWhether the transformations associated with the DIRT object are lower or upper triangular."
  },
  {
    "objectID": "reference/TTOptions.html",
    "href": "reference/TTOptions.html",
    "title": "TTOptions",
    "section": "",
    "text": "TTOptions(\n    self,\n    max_cross: int = 1,\n    cross_tol: float = 0.0001,\n    init_rank: int = 20,\n    kick_rank: int = 2,\n    max_rank: int = 30,\n    local_tol: float = 1e-10,\n    cdf_tol: float = 1e-10,\n    tt_method: str = 'amen',\n    int_method: str = 'maxvol',\n    verbose: bool = True,\n)\nOptions for configuring the construction of an FTT object.\n\n\n\nmax_cross : int = 1\n\nThe maximum number of cross iterations to be carried out during the FTT construction.\n\ncross_tol : float = 0.0001\n\nTODO\n\ninit_rank : int = 20\n\nThe initial rank of each tensor core.\n\nkick_rank : int = 2\n\nThe rank of the enrichment set of samples added at each cross iteration.\n\nmax_rank : int = 30\n\nThe maximum allowable rank of each tensor core.\n\nlocal_tol : float = 1e-10\n\nThe threshold to use when applying truncated SVD to the tensor cores when building the FTT.\n\ncdf_tol : float = 1e-10\n\nThe tolerance used when solving the root-finding problem to invert the CDF.\n\ntt_method : str = 'amen'\n\nThe method used to construct the TT cores. Can be 'fixed', 'random', or 'amen'.\n\nint_method : str = 'maxvol'\n\nThe interpolation method used when constructing the tensor cores. Can be 'maxvol' (Goreinov et al., 2010) or 'deim' (Chaturantabut and Sorensen, 2010).\n\nverbose : bool = True\n\nWhether to print the results of FTT construction to the screen at each iteration.\n\n\n\n\n\nChaturantabut, S and Sorensen, DC (2010). Nonlinear model reduction via discrete empirical interpolation. SIAM Journal on Scientific Computing 32, 2737–2764.\nGoreinov, SA, Oseledets, IV, Savostyanov, DV, Tyrtyshnikov, EE and Zamarashkin, NL (2010). How to find a good submatrix. In: Matrix Methods: Theory, Algorithms and Applications, 247–256.",
    "crumbs": [
      "API Reference",
      "Options",
      "TTOptions"
    ]
  },
  {
    "objectID": "reference/TTOptions.html#parameters",
    "href": "reference/TTOptions.html#parameters",
    "title": "TTOptions",
    "section": "",
    "text": "max_cross : int = 1\n\nThe maximum number of cross iterations to be carried out during the FTT construction.\n\ncross_tol : float = 0.0001\n\nTODO\n\ninit_rank : int = 20\n\nThe initial rank of each tensor core.\n\nkick_rank : int = 2\n\nThe rank of the enrichment set of samples added at each cross iteration.\n\nmax_rank : int = 30\n\nThe maximum allowable rank of each tensor core.\n\nlocal_tol : float = 1e-10\n\nThe threshold to use when applying truncated SVD to the tensor cores when building the FTT.\n\ncdf_tol : float = 1e-10\n\nThe tolerance used when solving the root-finding problem to invert the CDF.\n\ntt_method : str = 'amen'\n\nThe method used to construct the TT cores. Can be 'fixed', 'random', or 'amen'.\n\nint_method : str = 'maxvol'\n\nThe interpolation method used when constructing the tensor cores. Can be 'maxvol' (Goreinov et al., 2010) or 'deim' (Chaturantabut and Sorensen, 2010).\n\nverbose : bool = True\n\nWhether to print the results of FTT construction to the screen at each iteration.",
    "crumbs": [
      "API Reference",
      "Options",
      "TTOptions"
    ]
  },
  {
    "objectID": "reference/TTOptions.html#references",
    "href": "reference/TTOptions.html#references",
    "title": "TTOptions",
    "section": "",
    "text": "Chaturantabut, S and Sorensen, DC (2010). Nonlinear model reduction via discrete empirical interpolation. SIAM Journal on Scientific Computing 32, 2737–2764.\nGoreinov, SA, Oseledets, IV, Savostyanov, DV, Tyrtyshnikov, EE and Zamarashkin, NL (2010). How to find a good submatrix. In: Matrix Methods: Theory, Algorithms and Applications, 247–256.",
    "crumbs": [
      "API Reference",
      "Options",
      "TTOptions"
    ]
  },
  {
    "objectID": "reference/LagrangeP.html",
    "href": "reference/LagrangeP.html",
    "title": "LagrangeP",
    "section": "",
    "text": "LagrangeP(self, order: int, num_elems: int)\nHigher-order piecewise Lagrange polynomials.\n\n\n\norder : int\n\nThe degree of the polynomials, \\(n\\).\n\nnum_elems : int\n\nThe number of elements to use.\n\n\n\n\n\nTo construct a higher-order Lagrange basis, we divide the interval \\([0, 1]\\) into num_elems equisized elements, and use a set of Lagrange polynomials of degree \\(n=\\,\\)order within each element.\nWithin a given element, we choose a set of interpolation points, \\(\\{x_{j}\\}_{j=0}^{n}\\), which consist of the endpoints of the element and the roots of the Jacobi polynomial of degree \\(n-3\\) (mapped into the domain of the element). Then, a given function can be approximated (within the element) as \\[\n    f(x) \\approx \\sum_{j=0}^{n} f(x_{j})p_{j}(x),\n\\] where the Lagrange polynomials \\(\\{p_{j}(x)\\}_{j=0}^{n}\\) are given by \\[\n    p_{j}(x) = \\frac{\\prod_{k = 0, k \\neq j}^{n}(x-x_{k})}\n        {\\prod_{k = 0, k \\neq j}^{n}(x_{j}-x_{k})}.\n\\] To evaluate the interpolant, we use the second (true) form of the Barycentric formula, which is more efficient and stable than the above formula.\nWe use piecewise Chebyshev polynomials of the second kind to represent the (conditional) CDFs corresponding to the higher-order Lagrange representation of the (square root of) the target density function.\n\n\n\nBerrut, J and Trefethen, LN (2004). Barycentric Lagrange interpolation. SIAM Review, 46, 501–517.",
    "crumbs": [
      "API Reference",
      "Polynomial Bases",
      "LagrangeP"
    ]
  },
  {
    "objectID": "reference/LagrangeP.html#parameters",
    "href": "reference/LagrangeP.html#parameters",
    "title": "LagrangeP",
    "section": "",
    "text": "order : int\n\nThe degree of the polynomials, \\(n\\).\n\nnum_elems : int\n\nThe number of elements to use.",
    "crumbs": [
      "API Reference",
      "Polynomial Bases",
      "LagrangeP"
    ]
  },
  {
    "objectID": "reference/LagrangeP.html#notes",
    "href": "reference/LagrangeP.html#notes",
    "title": "LagrangeP",
    "section": "",
    "text": "To construct a higher-order Lagrange basis, we divide the interval \\([0, 1]\\) into num_elems equisized elements, and use a set of Lagrange polynomials of degree \\(n=\\,\\)order within each element.\nWithin a given element, we choose a set of interpolation points, \\(\\{x_{j}\\}_{j=0}^{n}\\), which consist of the endpoints of the element and the roots of the Jacobi polynomial of degree \\(n-3\\) (mapped into the domain of the element). Then, a given function can be approximated (within the element) as \\[\n    f(x) \\approx \\sum_{j=0}^{n} f(x_{j})p_{j}(x),\n\\] where the Lagrange polynomials \\(\\{p_{j}(x)\\}_{j=0}^{n}\\) are given by \\[\n    p_{j}(x) = \\frac{\\prod_{k = 0, k \\neq j}^{n}(x-x_{k})}\n        {\\prod_{k = 0, k \\neq j}^{n}(x_{j}-x_{k})}.\n\\] To evaluate the interpolant, we use the second (true) form of the Barycentric formula, which is more efficient and stable than the above formula.\nWe use piecewise Chebyshev polynomials of the second kind to represent the (conditional) CDFs corresponding to the higher-order Lagrange representation of the (square root of) the target density function.",
    "crumbs": [
      "API Reference",
      "Polynomial Bases",
      "LagrangeP"
    ]
  },
  {
    "objectID": "reference/LagrangeP.html#references",
    "href": "reference/LagrangeP.html#references",
    "title": "LagrangeP",
    "section": "",
    "text": "Berrut, J and Trefethen, LN (2004). Barycentric Lagrange interpolation. SIAM Review, 46, 501–517.",
    "crumbs": [
      "API Reference",
      "Polynomial Bases",
      "LagrangeP"
    ]
  },
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "API Reference",
    "section": "",
    "text": "An object used to generate an approximate coupling between random variables using a composition of squared inverse Rosenblatt transports, constructed using functional tensor trains.\n\n\n\nDIRT\nDeep (squared) inverse Rosenblatt transport.\n\n\n\n\n\n\nTriangular mappings which are used as starting points for DIRT construction.\n\n\n\nPreconditioner\nA mapping between the prior and a reference random variable.\n\n\nIdentityMapping\nAn identity mapping.\n\n\nUniformMapping\nA mapping between an arbitrary (product form) reference density\n\n\n\n\n\n\nPolynomial bases used to construct a functional tensor train.\n\n\n\nLagrange1\nPiecewise linear polynomials.\n\n\nLagrangeP\nHigher-order piecewise Lagrange polynomials.\n\n\nChebyshev1st\nChebyshev polynomials of the first kind.\n\n\nChebyshev2nd\nChebyshev polynomials of the second kind.\n\n\nFourier\nFourier polynomials.\n\n\nLegendre\nLegendre polynomials.\n\n\n\n\n\n\nMappings between the approximation domain and the domain of the polynomial basis.\n\n\n\nBoundedDomain\nMapping from a bounded domain to \\((-1, 1)\\).\n\n\nAlgebraicMapping\nMapping from an unbounded domain to \\((-1, 1)\\).\n\n\nLogarithmicMapping\nMapping from an unbounded domain to \\((-1, 1)\\).\n\n\n\n\n\n\nOptions for configuring the FTT and DIRT construction.\n\n\n\nTTOptions\nOptions for configuring the construction of an FTT object.\n\n\nDIRTOptions\nOptions for configuring the construction of a DIRT object.\n\n\n\n\n\n\nProduct-form reference densities used as part of DIRT construction.\n\n\n\nGaussianReference\nThe standard \\(d\\)-dimensional Gaussian density, \\(\\mathcal{N}(\\boldsymbol{0}_{d}, \\boldsymbol{I}_{d})\\).\n\n\nUniformReference\nThe standard \\(d\\)-dimensional uniform density, \\(\\mathcal{U}([0, 1]^{d})\\).\n\n\n\n\n\n\nObjects used to generate the intermediate densities approximated during DIRT construction.\n\n\n\nSingleLayer\nConstructs the DIRT using a single layer.\n\n\nTempering\nLikelihood tempering.\n\n\n\n\n\n\nFunctions used to remove the bias associated with the use of an approximation to the target density function.\n\n\n\nrun_importance_sampling\nComputes the importance weights associated with a set of samples.\n\n\nrun_independence_sampler\nRuns an independence MCMC sampler.\n\n\nrun_dirt_pcn\nRuns a preconditioned Crank-Nicholson (pCN) sampler.\n\n\nImportanceSamplingResult\nAn object containing the results of importance sampling.\n\n\nMCMCResult\nAn object containing a constructed Markov chain.",
    "crumbs": [
      "API Reference"
    ]
  },
  {
    "objectID": "reference/index.html#deep-inverse-rosenblatt-transport",
    "href": "reference/index.html#deep-inverse-rosenblatt-transport",
    "title": "API Reference",
    "section": "",
    "text": "An object used to generate an approximate coupling between random variables using a composition of squared inverse Rosenblatt transports, constructed using functional tensor trains.\n\n\n\nDIRT\nDeep (squared) inverse Rosenblatt transport.",
    "crumbs": [
      "API Reference"
    ]
  },
  {
    "objectID": "reference/index.html#preconditioners",
    "href": "reference/index.html#preconditioners",
    "title": "API Reference",
    "section": "",
    "text": "Triangular mappings which are used as starting points for DIRT construction.\n\n\n\nPreconditioner\nA mapping between the prior and a reference random variable.\n\n\nIdentityMapping\nAn identity mapping.\n\n\nUniformMapping\nA mapping between an arbitrary (product form) reference density",
    "crumbs": [
      "API Reference"
    ]
  },
  {
    "objectID": "reference/index.html#polynomial-bases",
    "href": "reference/index.html#polynomial-bases",
    "title": "API Reference",
    "section": "",
    "text": "Polynomial bases used to construct a functional tensor train.\n\n\n\nLagrange1\nPiecewise linear polynomials.\n\n\nLagrangeP\nHigher-order piecewise Lagrange polynomials.\n\n\nChebyshev1st\nChebyshev polynomials of the first kind.\n\n\nChebyshev2nd\nChebyshev polynomials of the second kind.\n\n\nFourier\nFourier polynomials.\n\n\nLegendre\nLegendre polynomials.",
    "crumbs": [
      "API Reference"
    ]
  },
  {
    "objectID": "reference/index.html#domain-mappings",
    "href": "reference/index.html#domain-mappings",
    "title": "API Reference",
    "section": "",
    "text": "Mappings between the approximation domain and the domain of the polynomial basis.\n\n\n\nBoundedDomain\nMapping from a bounded domain to \\((-1, 1)\\).\n\n\nAlgebraicMapping\nMapping from an unbounded domain to \\((-1, 1)\\).\n\n\nLogarithmicMapping\nMapping from an unbounded domain to \\((-1, 1)\\).",
    "crumbs": [
      "API Reference"
    ]
  },
  {
    "objectID": "reference/index.html#options",
    "href": "reference/index.html#options",
    "title": "API Reference",
    "section": "",
    "text": "Options for configuring the FTT and DIRT construction.\n\n\n\nTTOptions\nOptions for configuring the construction of an FTT object.\n\n\nDIRTOptions\nOptions for configuring the construction of a DIRT object.",
    "crumbs": [
      "API Reference"
    ]
  },
  {
    "objectID": "reference/index.html#reference-densities",
    "href": "reference/index.html#reference-densities",
    "title": "API Reference",
    "section": "",
    "text": "Product-form reference densities used as part of DIRT construction.\n\n\n\nGaussianReference\nThe standard \\(d\\)-dimensional Gaussian density, \\(\\mathcal{N}(\\boldsymbol{0}_{d}, \\boldsymbol{I}_{d})\\).\n\n\nUniformReference\nThe standard \\(d\\)-dimensional uniform density, \\(\\mathcal{U}([0, 1]^{d})\\).",
    "crumbs": [
      "API Reference"
    ]
  },
  {
    "objectID": "reference/index.html#bridges",
    "href": "reference/index.html#bridges",
    "title": "API Reference",
    "section": "",
    "text": "Objects used to generate the intermediate densities approximated during DIRT construction.\n\n\n\nSingleLayer\nConstructs the DIRT using a single layer.\n\n\nTempering\nLikelihood tempering.",
    "crumbs": [
      "API Reference"
    ]
  },
  {
    "objectID": "reference/index.html#debiasing",
    "href": "reference/index.html#debiasing",
    "title": "API Reference",
    "section": "",
    "text": "Functions used to remove the bias associated with the use of an approximation to the target density function.\n\n\n\nrun_importance_sampling\nComputes the importance weights associated with a set of samples.\n\n\nrun_independence_sampler\nRuns an independence MCMC sampler.\n\n\nrun_dirt_pcn\nRuns a preconditioned Crank-Nicholson (pCN) sampler.\n\n\nImportanceSamplingResult\nAn object containing the results of importance sampling.\n\n\nMCMCResult\nAn object containing a constructed Markov chain.",
    "crumbs": [
      "API Reference"
    ]
  },
  {
    "objectID": "reference/Chebyshev1st.html",
    "href": "reference/Chebyshev1st.html",
    "title": "Chebyshev1st",
    "section": "",
    "text": "Chebyshev1st(self, order: int)\nChebyshev polynomials of the first kind.\n\n\n\norder : int\n\nThe maximum order of the polynomials.\n\n\n\n\n\nThe (normalised) Chebyshev polynomials of the first kind, defined on \\((-1, 1)\\), are given by \\[\n\\begin{align}\n    p_{0}(x) &= 1, \\\\\n    p_{k}(x) &= \\sqrt{2}\\cos(k\\arccos(x)),\n        \\qquad k = 1, 2, \\dots, n.\n\\end{align}\n\\] The polynomials are orthogonal with respect to the (normalised) weighting function given by \\[\n    \\lambda(x) = \\frac{1}{\\pi\\sqrt{1-x^{2}}}.\n\\]\n\n\n\nBoyd, JP (2001, Appendix A.2). Chebyshev and Fourier spectral methods. Lecture Notes in Engineering, Volume 49.\nCui, T, Dolgov, S and Zahm, O (2023). Self-reinforced polynomial approximation methods for concentrated probability densities. arXiv preprint.",
    "crumbs": [
      "API Reference",
      "Polynomial Bases",
      "Chebyshev1st"
    ]
  },
  {
    "objectID": "reference/Chebyshev1st.html#parameters",
    "href": "reference/Chebyshev1st.html#parameters",
    "title": "Chebyshev1st",
    "section": "",
    "text": "order : int\n\nThe maximum order of the polynomials.",
    "crumbs": [
      "API Reference",
      "Polynomial Bases",
      "Chebyshev1st"
    ]
  },
  {
    "objectID": "reference/Chebyshev1st.html#notes",
    "href": "reference/Chebyshev1st.html#notes",
    "title": "Chebyshev1st",
    "section": "",
    "text": "The (normalised) Chebyshev polynomials of the first kind, defined on \\((-1, 1)\\), are given by \\[\n\\begin{align}\n    p_{0}(x) &= 1, \\\\\n    p_{k}(x) &= \\sqrt{2}\\cos(k\\arccos(x)),\n        \\qquad k = 1, 2, \\dots, n.\n\\end{align}\n\\] The polynomials are orthogonal with respect to the (normalised) weighting function given by \\[\n    \\lambda(x) = \\frac{1}{\\pi\\sqrt{1-x^{2}}}.\n\\]",
    "crumbs": [
      "API Reference",
      "Polynomial Bases",
      "Chebyshev1st"
    ]
  },
  {
    "objectID": "reference/Chebyshev1st.html#references",
    "href": "reference/Chebyshev1st.html#references",
    "title": "Chebyshev1st",
    "section": "",
    "text": "Boyd, JP (2001, Appendix A.2). Chebyshev and Fourier spectral methods. Lecture Notes in Engineering, Volume 49.\nCui, T, Dolgov, S and Zahm, O (2023). Self-reinforced polynomial approximation methods for concentrated probability densities. arXiv preprint.",
    "crumbs": [
      "API Reference",
      "Polynomial Bases",
      "Chebyshev1st"
    ]
  },
  {
    "objectID": "reference/run_dirt_pcn.html",
    "href": "reference/run_dirt_pcn.html",
    "title": "run_dirt_pcn",
    "section": "",
    "text": "run_dirt_pcn(\n    potential: Callable[[Tensor], Tensor],\n    dirt: AbstractDIRT,\n    n: float,\n    dt: float = 2.0,\n    y_obs: Tensor | None = None,\n    x0: Tensor | None = None,\n    subset: str = 'first',\n    verbose: bool = True,\n)\nRuns a preconditioned Crank-Nicholson (pCN) sampler.\nRuns a pCN sampler (Cotter et al., 2013) to characterise the pullback of the target density under the DIRT mapping, then pushes the resulting samples forward under the DIRT mapping to obtain samples distributed according to the target. This idea was initially outlined by Cui et al. (2023).\nNote that the pCN proposal is only applicable to problems with a Gaussian reference density.\nTODO: record IACT somewhere. Might need to use an external library for this one.\n\n\n\npotential : Callable[[Tensor], Tensor]\n\nA function that returns the negative logarithm of the (possibly unnormalised) target density at a given sample.\n\ndirt : AbstractDIRT\n\nA previously-constructed DIRT object.\n\ny_obs : Tensor | None = None\n\nA tensor containing the observations.\n\nn : float\n\nThe length of the Markov chain to construct.\n\ndt : float = 2.0\n\npCN stepsize, \\(\\Delta t\\). If this is not specified, a value of \\(\\Delta t = 2\\) (independence sampler) will be used.\n\nx0 : Tensor | None = None\n\nThe starting state. If this is passed in, the DIRT mapping will be applied to it to generate the starting location for sampling from the pullback of the target density. Otherwise, the mean of the reference density will be used.\n\nverbose : bool = True\n\nWhether to print diagnostic information during the sampling process.\n\n\n\n\n\n\nres : MCMCResult\n\nAn object containing the constructed Markov chain and some diagnostic information.\n\n\n\n\n\nWhen the reference density is the standard Gaussian density (that is, \\(\\rho(\\theta) = \\mathcal{N}(0_{d}, I_{d})\\)), the pCN proposal (given current state \\(\\theta^{(i)}\\)) takes the form \\[\n    \\theta' = \\frac{2-\\Delta t}{2+\\Delta t} \\theta^{(i)}\n        + \\frac{2\\sqrt{2\\Delta t}}{2 + \\Delta t} \\tilde{\\theta},\n\\] where \\(\\tilde{\\theta} \\sim \\rho(\\,\\cdot\\,)\\), and \\(\\Delta t\\) denotes the step size.\nWhen \\(\\Delta t = 2\\), the resulting sampler is an independence sampler. When \\(\\Delta t &gt; 2\\), the proposals are negatively correlated, and when \\(\\Delta t &lt; 2\\), the proposals are positively correlated.\n\n\n\nCotter, SL, Roberts, GO, Stuart, AM and White, D (2013). MCMC methods for functions: Modifying old algorithms to make them faster. Statistical Science 28, 424–446.\nCui, T, Dolgov, S and Zahm, O (2023). Scalable conditional deep inverse Rosenblatt transports using tensor trains and gradient-based dimension reduction. Journal of Computational Physics 485, 112103.",
    "crumbs": [
      "API Reference",
      "Debiasing",
      "run_dirt_pcn"
    ]
  },
  {
    "objectID": "reference/run_dirt_pcn.html#parameters",
    "href": "reference/run_dirt_pcn.html#parameters",
    "title": "run_dirt_pcn",
    "section": "",
    "text": "potential : Callable[[Tensor], Tensor]\n\nA function that returns the negative logarithm of the (possibly unnormalised) target density at a given sample.\n\ndirt : AbstractDIRT\n\nA previously-constructed DIRT object.\n\ny_obs : Tensor | None = None\n\nA tensor containing the observations.\n\nn : float\n\nThe length of the Markov chain to construct.\n\ndt : float = 2.0\n\npCN stepsize, \\(\\Delta t\\). If this is not specified, a value of \\(\\Delta t = 2\\) (independence sampler) will be used.\n\nx0 : Tensor | None = None\n\nThe starting state. If this is passed in, the DIRT mapping will be applied to it to generate the starting location for sampling from the pullback of the target density. Otherwise, the mean of the reference density will be used.\n\nverbose : bool = True\n\nWhether to print diagnostic information during the sampling process.",
    "crumbs": [
      "API Reference",
      "Debiasing",
      "run_dirt_pcn"
    ]
  },
  {
    "objectID": "reference/run_dirt_pcn.html#returns",
    "href": "reference/run_dirt_pcn.html#returns",
    "title": "run_dirt_pcn",
    "section": "",
    "text": "res : MCMCResult\n\nAn object containing the constructed Markov chain and some diagnostic information.",
    "crumbs": [
      "API Reference",
      "Debiasing",
      "run_dirt_pcn"
    ]
  },
  {
    "objectID": "reference/run_dirt_pcn.html#notes",
    "href": "reference/run_dirt_pcn.html#notes",
    "title": "run_dirt_pcn",
    "section": "",
    "text": "When the reference density is the standard Gaussian density (that is, \\(\\rho(\\theta) = \\mathcal{N}(0_{d}, I_{d})\\)), the pCN proposal (given current state \\(\\theta^{(i)}\\)) takes the form \\[\n    \\theta' = \\frac{2-\\Delta t}{2+\\Delta t} \\theta^{(i)}\n        + \\frac{2\\sqrt{2\\Delta t}}{2 + \\Delta t} \\tilde{\\theta},\n\\] where \\(\\tilde{\\theta} \\sim \\rho(\\,\\cdot\\,)\\), and \\(\\Delta t\\) denotes the step size.\nWhen \\(\\Delta t = 2\\), the resulting sampler is an independence sampler. When \\(\\Delta t &gt; 2\\), the proposals are negatively correlated, and when \\(\\Delta t &lt; 2\\), the proposals are positively correlated.",
    "crumbs": [
      "API Reference",
      "Debiasing",
      "run_dirt_pcn"
    ]
  },
  {
    "objectID": "reference/run_dirt_pcn.html#references",
    "href": "reference/run_dirt_pcn.html#references",
    "title": "run_dirt_pcn",
    "section": "",
    "text": "Cotter, SL, Roberts, GO, Stuart, AM and White, D (2013). MCMC methods for functions: Modifying old algorithms to make them faster. Statistical Science 28, 424–446.\nCui, T, Dolgov, S and Zahm, O (2023). Scalable conditional deep inverse Rosenblatt transports using tensor trains and gradient-based dimension reduction. Journal of Computational Physics 485, 112103.",
    "crumbs": [
      "API Reference",
      "Debiasing",
      "run_dirt_pcn"
    ]
  },
  {
    "objectID": "reference/LogarithmicMapping.html",
    "href": "reference/LogarithmicMapping.html",
    "title": "LogarithmicMapping",
    "section": "",
    "text": "LogarithmicMapping(self, scale: float | Tensor = 1.0)\nMapping from an unbounded domain to \\((-1, 1)\\).\nThis class provides a mapping from an unbounded domain, \\((-\\infty, \\infty)\\), to a bounded domain, \\((-1, 1)\\). This mapping is of the form \\[x \\mapsto \\tanh\\left(\\frac{x}{s}\\right),\\] where \\(s\\) is a scale parameter.\n\n\n\nscale : float | Tensor = 1.0\n\nThe scale parameter, \\(s\\).",
    "crumbs": [
      "API Reference",
      "Domain Mappings",
      "LogarithmicMapping"
    ]
  },
  {
    "objectID": "reference/LogarithmicMapping.html#parameters",
    "href": "reference/LogarithmicMapping.html#parameters",
    "title": "LogarithmicMapping",
    "section": "",
    "text": "scale : float | Tensor = 1.0\n\nThe scale parameter, \\(s\\).",
    "crumbs": [
      "API Reference",
      "Domain Mappings",
      "LogarithmicMapping"
    ]
  },
  {
    "objectID": "reference/Chebyshev2nd.html",
    "href": "reference/Chebyshev2nd.html",
    "title": "Chebyshev2nd",
    "section": "",
    "text": "Chebyshev2nd(self, order: int)\nChebyshev polynomials of the second kind.\n\n\n\norder : int\n\nThe maximum order of the polynomials.\n\n\n\n\n\nThe (normalised) Chebyshev polynomials of the second kind, defined on \\((-1, 1)\\), are given by \\[\n    p_{k}(x) = \\frac{\\sin((k+1)\\arccos(x))}{\\sin{(\\arccos(x))}},\n        \\qquad k = 0, 1, \\dots, n.\n\\] The polynomials are orthogonal with respect to the (normalised) weighting function given by \\[\n    \\lambda(x) = \\frac{2\\sqrt{1-x^{2}}}{\\pi}.\n\\]\n\n\n\nBoyd, JP (2001, Appendix A.2). Chebyshev and Fourier spectral methods. Lecture Notes in Engineering, Volume 49.",
    "crumbs": [
      "API Reference",
      "Polynomial Bases",
      "Chebyshev2nd"
    ]
  },
  {
    "objectID": "reference/Chebyshev2nd.html#parameters",
    "href": "reference/Chebyshev2nd.html#parameters",
    "title": "Chebyshev2nd",
    "section": "",
    "text": "order : int\n\nThe maximum order of the polynomials.",
    "crumbs": [
      "API Reference",
      "Polynomial Bases",
      "Chebyshev2nd"
    ]
  },
  {
    "objectID": "reference/Chebyshev2nd.html#notes",
    "href": "reference/Chebyshev2nd.html#notes",
    "title": "Chebyshev2nd",
    "section": "",
    "text": "The (normalised) Chebyshev polynomials of the second kind, defined on \\((-1, 1)\\), are given by \\[\n    p_{k}(x) = \\frac{\\sin((k+1)\\arccos(x))}{\\sin{(\\arccos(x))}},\n        \\qquad k = 0, 1, \\dots, n.\n\\] The polynomials are orthogonal with respect to the (normalised) weighting function given by \\[\n    \\lambda(x) = \\frac{2\\sqrt{1-x^{2}}}{\\pi}.\n\\]",
    "crumbs": [
      "API Reference",
      "Polynomial Bases",
      "Chebyshev2nd"
    ]
  },
  {
    "objectID": "reference/Chebyshev2nd.html#references",
    "href": "reference/Chebyshev2nd.html#references",
    "title": "Chebyshev2nd",
    "section": "",
    "text": "Boyd, JP (2001, Appendix A.2). Chebyshev and Fourier spectral methods. Lecture Notes in Engineering, Volume 49.",
    "crumbs": [
      "API Reference",
      "Polynomial Bases",
      "Chebyshev2nd"
    ]
  },
  {
    "objectID": "reference/run_independence_sampler.html",
    "href": "reference/run_independence_sampler.html",
    "title": "run_independence_sampler",
    "section": "",
    "text": "run_independence_sampler(\n    xs: Tensor,\n    neglogfxs_irt: Tensor,\n    neglogfxs_exact: Tensor,\n)\nRuns an independence MCMC sampler.\nRuns an independence MCMC sampler using a set of samples from a SIRT or DIRT object as the proposal.\n\n\n\nxs : Tensor\n\nAn \\(n \\times d\\) matrix containing independent samples from the DIRT object.\n\nneglogfxs_irt : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function associated with the DIRT object evaluated at each sample.\n\nneglogfxs_exact : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function associated with the target density evaluated at each sample.\n\n\n\n\n\n\nres : MCMCResult\n\nAn object containing the constructed Markov chain and some diagnostic information.",
    "crumbs": [
      "API Reference",
      "Debiasing",
      "run_independence_sampler"
    ]
  },
  {
    "objectID": "reference/run_independence_sampler.html#parameters",
    "href": "reference/run_independence_sampler.html#parameters",
    "title": "run_independence_sampler",
    "section": "",
    "text": "xs : Tensor\n\nAn \\(n \\times d\\) matrix containing independent samples from the DIRT object.\n\nneglogfxs_irt : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function associated with the DIRT object evaluated at each sample.\n\nneglogfxs_exact : Tensor\n\nAn \\(n\\)-dimensional vector containing the potential function associated with the target density evaluated at each sample.",
    "crumbs": [
      "API Reference",
      "Debiasing",
      "run_independence_sampler"
    ]
  },
  {
    "objectID": "reference/run_independence_sampler.html#returns",
    "href": "reference/run_independence_sampler.html#returns",
    "title": "run_independence_sampler",
    "section": "",
    "text": "res : MCMCResult\n\nAn object containing the constructed Markov chain and some diagnostic information.",
    "crumbs": [
      "API Reference",
      "Debiasing",
      "run_independence_sampler"
    ]
  },
  {
    "objectID": "reference/MCMCResult.html",
    "href": "reference/MCMCResult.html",
    "title": "MCMCResult",
    "section": "",
    "text": "MCMCResult(self, xs: Tensor, acceptance_rate: Tensor)\nAn object containing a constructed Markov chain.\n\n\n\nxs : Tensor\n\nAn \\(n \\times d\\) matrix containing the samples that form the Markov chain.\n\nacceptance_rate : Tensor\n\nThe acceptance rate of the sampler.",
    "crumbs": [
      "API Reference",
      "Debiasing",
      "MCMCResult"
    ]
  },
  {
    "objectID": "reference/MCMCResult.html#parameters",
    "href": "reference/MCMCResult.html#parameters",
    "title": "MCMCResult",
    "section": "",
    "text": "xs : Tensor\n\nAn \\(n \\times d\\) matrix containing the samples that form the Markov chain.\n\nacceptance_rate : Tensor\n\nThe acceptance rate of the sampler.",
    "crumbs": [
      "API Reference",
      "Debiasing",
      "MCMCResult"
    ]
  },
  {
    "objectID": "reference/DIRTOptions.html",
    "href": "reference/DIRTOptions.html",
    "title": "DIRTOptions",
    "section": "",
    "text": "DIRTOptions(\n    self,\n    method: str = 'aratio',\n    num_samples: int = 1000,\n    num_debugs: int = 1000,\n    defensive: float = 1e-08,\n    verbose: bool = True,\n)\nOptions for configuring the construction of a DIRT object.\n\n\n\nmethod : str = 'aratio'\n\nThe method used for the ratio function at each iteration. Can be 'aratio' (approximate ratio) or 'eratio' (exact ratio).\n\nnum_samples : int = 1000\n\nTODO: remove this eventually.\n\nnum_debugs : int = 1000\n\nThe number of samples used to evaluate the quality of each SIRT constructed during the construction of the DIRT.\n\ndefensive : float = 1e-08\n\nThe parameter (often referred to as \\(\\gamma\\) or \\(\\tau\\)) used to make the tails of the FTT approximation to each ratio function heavier.\n\nverbose : bool = True\n\nWhether to print information on the construction of the DIRT object.",
    "crumbs": [
      "API Reference",
      "Options",
      "DIRTOptions"
    ]
  },
  {
    "objectID": "reference/DIRTOptions.html#parameters",
    "href": "reference/DIRTOptions.html#parameters",
    "title": "DIRTOptions",
    "section": "",
    "text": "method : str = 'aratio'\n\nThe method used for the ratio function at each iteration. Can be 'aratio' (approximate ratio) or 'eratio' (exact ratio).\n\nnum_samples : int = 1000\n\nTODO: remove this eventually.\n\nnum_debugs : int = 1000\n\nThe number of samples used to evaluate the quality of each SIRT constructed during the construction of the DIRT.\n\ndefensive : float = 1e-08\n\nThe parameter (often referred to as \\(\\gamma\\) or \\(\\tau\\)) used to make the tails of the FTT approximation to each ratio function heavier.\n\nverbose : bool = True\n\nWhether to print information on the construction of the DIRT object.",
    "crumbs": [
      "API Reference",
      "Options",
      "DIRTOptions"
    ]
  },
  {
    "objectID": "reference/Tempering.html",
    "href": "reference/Tempering.html",
    "title": "Tempering",
    "section": "",
    "text": "Tempering(\n    self,\n    betas: Tensor | None = None,\n    ess_tol: Tensor | float = 0.5,\n    ess_tol_init: Tensor | float = 0.5,\n    beta_factor: Tensor | float = 1.05,\n    min_beta: Tensor | float = 0.0001,\n    max_layers: int = 20,\n)\nLikelihood tempering.\nThe intermediate densities, \\(\\{\\pi_{k}(\\theta)\\}_{k=1}^{N}\\), generated using this approach take the form \\[\\pi_{k}(\\theta) \\propto \\pi_{0}(\\theta)\\mathcal{L}(\\theta; y)^{\\beta_{k}},\\] where \\(\\pi_{0}(\\,\\cdot\\,)\\) denotes the prior, \\(\\mathcal{L}(\\,\\cdot\\,; y)\\) denotes the likelihood, and \\(0 \\leq \\beta_{1} &lt; \\cdots &lt; \\beta_{N} = 1\\).\nIt is possible to provide this class with a set of \\(\\beta\\) values to use. If these are not provided, they will be determined automatically by finding the largest possible \\(\\beta\\), at each iteration, such that the ESS of a reweighted set of samples distributed according to (a TT approximation to) the previous bridging density does not fall below a given value.\n\n\n\nbetas : Tensor | None = None\n\nA set of \\(\\beta\\) values to use for the intermediate distributions. If not specified, these will be determined automatically.\n\ness_tol : Tensor | float = 0.5\n\nIf selecting the \\(\\beta\\) values adaptively, the minimum allowable ESS of the samples (distributed according to an approximation of the previous bridging density) when selecting the next bridging density.\n\ness_tol_init : Tensor | float = 0.5\n\nIf selecting the \\(\\beta\\) values adaptively, the minimum allowable ESS of the samples when selecting the initial bridging density.\n\nbeta_factor : Tensor | float = 1.05\n\nIf selecting the \\(\\beta\\) values adaptively, the factor by which to increase the current \\(\\beta\\) value by prior to checking whether the ESS of the reweighted samples is sufficiently high.\n\nmin_beta : Tensor | float = 0.0001\n\nIf selecting the \\(\\beta\\) values adaptively, the minimum allowable \\(\\beta\\) value.\n\nmax_layers : int = 20\n\nIf selecting the \\(\\beta\\) values adaptively, the maximum number of layers to construct. Note that, if the maximum number of layers is reached, the final bridging density may not be equal to the posterior.",
    "crumbs": [
      "API Reference",
      "Bridges",
      "Tempering"
    ]
  },
  {
    "objectID": "reference/Tempering.html#parameters",
    "href": "reference/Tempering.html#parameters",
    "title": "Tempering",
    "section": "",
    "text": "betas : Tensor | None = None\n\nA set of \\(\\beta\\) values to use for the intermediate distributions. If not specified, these will be determined automatically.\n\ness_tol : Tensor | float = 0.5\n\nIf selecting the \\(\\beta\\) values adaptively, the minimum allowable ESS of the samples (distributed according to an approximation of the previous bridging density) when selecting the next bridging density.\n\ness_tol_init : Tensor | float = 0.5\n\nIf selecting the \\(\\beta\\) values adaptively, the minimum allowable ESS of the samples when selecting the initial bridging density.\n\nbeta_factor : Tensor | float = 1.05\n\nIf selecting the \\(\\beta\\) values adaptively, the factor by which to increase the current \\(\\beta\\) value by prior to checking whether the ESS of the reweighted samples is sufficiently high.\n\nmin_beta : Tensor | float = 0.0001\n\nIf selecting the \\(\\beta\\) values adaptively, the minimum allowable \\(\\beta\\) value.\n\nmax_layers : int = 20\n\nIf selecting the \\(\\beta\\) values adaptively, the maximum number of layers to construct. Note that, if the maximum number of layers is reached, the final bridging density may not be equal to the posterior.",
    "crumbs": [
      "API Reference",
      "Bridges",
      "Tempering"
    ]
  }
]